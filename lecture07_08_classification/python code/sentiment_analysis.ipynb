{"cells":[{"cell_type":"markdown","metadata":{"id":"BPYUnIjfxIRP"},"source":["# Introduction to Spark ML: An application to Sentiment Analysis"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47477,"status":"ok","timestamp":1667173608259,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"8NFmfL6uv56m","outputId":"f7d0830f-d0e8-418a-d0e5-798fbf5546f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n","Collecting py4j==0.10.9.5\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py): started\n","  Building wheel for pyspark (setup.py): finished with status 'done'\n","  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845513 sha256=b857264852d7bae9b9b1602deb0df8211584a90f078bece64798762691bfae3e\n","  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"]}],"source":["%%bash \n","# Do not change or modify this cell\n","# Need to install pyspark\n","# if pyspark is already installed, will print a message indicating requirement already satisfied\n","pip install pyspark"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1155,"status":"ok","timestamp":1667173609408,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"iEd0Y8MMQagS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2279fd27-8014-496b-a846-528298067b98"},"outputs":[{"output_type":"stream","name":"stderr","text":["--2022-10-30 23:46:47--  https://raw.githubusercontent.com/wewilli1/ist718_data/master/imdb_reviews_preprocessed.parquet\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 21597134 (21M) [application/octet-stream]\n","Saving to: ‘imdb_reviews_preprocessed.parquet’\n","\n","     0K .......... .......... .......... .......... ..........  0% 4.34M 5s\n","    50K .......... .......... .......... .......... ..........  0% 5.17M 4s\n","   100K .......... .......... .......... .......... ..........  0% 21.4M 3s\n","   150K .......... .......... .......... .......... ..........  0% 19.4M 3s\n","   200K .......... .......... .......... .......... ..........  1% 8.47M 3s\n","   250K .......... .......... .......... .......... ..........  1% 38.8M 2s\n","   300K .......... .......... .......... .......... ..........  1% 38.5M 2s\n","   350K .......... .......... .......... .......... ..........  1% 38.5M 2s\n","   400K .......... .......... .......... .......... ..........  2% 42.3M 2s\n","   450K .......... .......... .......... .......... ..........  2% 45.2M 2s\n","   500K .......... .......... .......... .......... ..........  2% 10.3M 2s\n","   550K .......... .......... .......... .......... ..........  2% 37.0M 1s\n","   600K .......... .......... .......... .......... ..........  3% 45.5M 1s\n","   650K .......... .......... .......... .......... ..........  3% 45.6M 1s\n","   700K .......... .......... .......... .......... ..........  3% 41.7M 1s\n","   750K .......... .......... .......... .......... ..........  3%  145M 1s\n","   800K .......... .......... .......... .......... ..........  4%  222M 1s\n","   850K .......... .......... .......... .......... ..........  4%  249M 1s\n","   900K .......... .......... .......... .......... ..........  4%  234M 1s\n","   950K .......... .......... .......... .......... ..........  4%  216M 1s\n","  1000K .......... .......... .......... .......... ..........  4% 6.97M 1s\n","  1050K .......... .......... .......... .......... ..........  5% 39.6M 1s\n","  1100K .......... .......... .......... .......... ..........  5% 36.1M 1s\n","  1150K .......... .......... .......... .......... ..........  5% 35.2M 1s\n","  1200K .......... .......... .......... .......... ..........  5% 48.7M 1s\n","  1250K .......... .......... .......... .......... ..........  6%  103M 1s\n","  1300K .......... .......... .......... .......... ..........  6%  252M 1s\n","  1350K .......... .......... .......... .......... ..........  6%  202M 1s\n","  1400K .......... .......... .......... .......... ..........  6%  246M 1s\n","  1450K .......... .......... .......... .......... ..........  7%  247M 1s\n","  1500K .......... .......... .......... .......... ..........  7%  216M 1s\n","  1550K .......... .......... .......... .......... ..........  7%  210M 1s\n","  1600K .......... .......... .......... .......... ..........  7%  254M 1s\n","  1650K .......... .......... .......... .......... ..........  8%  155M 1s\n","  1700K .......... .......... .......... .......... ..........  8%  174M 1s\n","  1750K .......... .......... .......... .......... ..........  8%  230M 1s\n","  1800K .......... .......... .......... .......... ..........  8%  250M 1s\n","  1850K .......... .......... .......... .......... ..........  9%  217M 1s\n","  1900K .......... .......... .......... .......... ..........  9% 10.4M 1s\n","  1950K .......... .......... .......... .......... ..........  9% 35.2M 1s\n","  2000K .......... .......... .......... .......... ..........  9% 33.8M 1s\n","  2050K .......... .......... .......... .......... ..........  9% 40.8M 1s\n","  2100K .......... .......... .......... .......... .......... 10% 41.8M 1s\n","  2150K .......... .......... .......... .......... .......... 10% 47.0M 1s\n","  2200K .......... .......... .......... .......... .......... 10% 39.2M 1s\n","  2250K .......... .......... .......... .......... .......... 10% 39.1M 1s\n","  2300K .......... .......... .......... .......... .......... 11% 44.0M 1s\n","  2350K .......... .......... .......... .......... .......... 11% 47.1M 1s\n","  2400K .......... .......... .......... .......... .......... 11% 46.4M 1s\n","  2450K .......... .......... .......... .......... .......... 11% 41.0M 1s\n","  2500K .......... .......... .......... .......... .......... 12% 95.4M 1s\n","  2550K .......... .......... .......... .......... .......... 12%  149M 1s\n","  2600K .......... .......... .......... .......... .......... 12%  127M 1s\n","  2650K .......... .......... .......... .......... .......... 12% 23.4M 1s\n","  2700K .......... .......... .......... .......... .......... 13% 43.6M 1s\n","  2750K .......... .......... .......... .......... .......... 13% 44.4M 1s\n","  2800K .......... .......... .......... .......... .......... 13% 39.9M 1s\n","  2850K .......... .......... .......... .......... .......... 13%  206M 1s\n","  2900K .......... .......... .......... .......... .......... 13%  261M 1s\n","  2950K .......... .......... .......... .......... .......... 14%  219M 1s\n","  3000K .......... .......... .......... .......... .......... 14%  231M 1s\n","  3050K .......... .......... .......... .......... .......... 14%  213M 1s\n","  3100K .......... .......... .......... .......... .......... 14%  248M 1s\n","  3150K .......... .......... .......... .......... .......... 15%  253M 0s\n","  3200K .......... .......... .......... .......... .......... 15% 57.4M 0s\n","  3250K .......... .......... .......... .......... .......... 15% 33.5M 0s\n","  3300K .......... .......... .......... .......... .......... 15% 38.3M 0s\n","  3350K .......... .......... .......... .......... .......... 16% 44.8M 0s\n","  3400K .......... .......... .......... .......... .......... 16% 33.6M 0s\n","  3450K .......... .......... .......... .......... .......... 16%  112M 0s\n","  3500K .......... .......... .......... .......... .......... 16%  194M 0s\n","  3550K .......... .......... .......... .......... .......... 17%  207M 0s\n","  3600K .......... .......... .......... .......... .......... 17%  213M 0s\n","  3650K .......... .......... .......... .......... .......... 17%  186M 0s\n","  3700K .......... .......... .......... .......... .......... 17%  232M 0s\n","  3750K .......... .......... .......... .......... .......... 18%  163M 0s\n","  3800K .......... .......... .......... .......... .......... 18%  178M 0s\n","  3850K .......... .......... .......... .......... .......... 18%  164M 0s\n","  3900K .......... .......... .......... .......... .......... 18%  233M 0s\n","  3950K .......... .......... .......... .......... .......... 18%  244M 0s\n","  4000K .......... .......... .......... .......... .......... 19%  223M 0s\n","  4050K .......... .......... .......... .......... .......... 19%  191M 0s\n","  4100K .......... .......... .......... .......... .......... 19%  250M 0s\n","  4150K .......... .......... .......... .......... .......... 19%  244M 0s\n","  4200K .......... .......... .......... .......... .......... 20%  223M 0s\n","  4250K .......... .......... .......... .......... .......... 20%  213M 0s\n","  4300K .......... .......... .......... .......... .......... 20%  214M 0s\n","  4350K .......... .......... .......... .......... .......... 20%  238M 0s\n","  4400K .......... .......... .......... .......... .......... 21%  250M 0s\n","  4450K .......... .......... .......... .......... .......... 21% 59.6M 0s\n","  4500K .......... .......... .......... .......... .......... 21% 49.0M 0s\n","  4550K .......... .......... .......... .......... .......... 21% 35.3M 0s\n","  4600K .......... .......... .......... .......... .......... 22% 46.5M 0s\n","  4650K .......... .......... .......... .......... .......... 22% 35.0M 0s\n","  4700K .......... .......... .......... .......... .......... 22% 43.0M 0s\n","  4750K .......... .......... .......... .......... .......... 22% 45.7M 0s\n","  4800K .......... .......... .......... .......... .......... 22% 42.3M 0s\n","  4850K .......... .......... .......... .......... .......... 23% 39.6M 0s\n","  4900K .......... .......... .......... .......... .......... 23% 46.2M 0s\n","  4950K .......... .......... .......... .......... .......... 23% 46.0M 0s\n","  5000K .......... .......... .......... .......... .......... 23% 37.2M 0s\n","  5050K .......... .......... .......... .......... .......... 24% 42.4M 0s\n","  5100K .......... .......... .......... .......... .......... 24% 38.6M 0s\n","  5150K .......... .......... .......... .......... .......... 24% 42.4M 0s\n","  5200K .......... .......... .......... .......... .......... 24% 71.8M 0s\n","  5250K .......... .......... .......... .......... .......... 25%  151M 0s\n","  5300K .......... .......... .......... .......... .......... 25%  233M 0s\n","  5350K .......... .......... .......... .......... .......... 25%  180M 0s\n","  5400K .......... .......... .......... .......... .......... 25%  249M 0s\n","  5450K .......... .......... .......... .......... .......... 26%  212M 0s\n","  5500K .......... .......... .......... .......... .......... 26%  243M 0s\n","  5550K .......... .......... .......... .......... .......... 26%  220M 0s\n","  5600K .......... .......... .......... .......... .......... 26%  244M 0s\n","  5650K .......... .......... .......... .......... .......... 27%  206M 0s\n","  5700K .......... .......... .......... .......... .......... 27%  225M 0s\n","  5750K .......... .......... .......... .......... .......... 27%  242M 0s\n","  5800K .......... .......... .......... .......... .......... 27%  223M 0s\n","  5850K .......... .......... .......... .......... .......... 27%  229M 0s\n","  5900K .......... .......... .......... .......... .......... 28%  258M 0s\n","  5950K .......... .......... .......... .......... .......... 28%  231M 0s\n","  6000K .......... .......... .......... .......... .......... 28%  249M 0s\n","  6050K .......... .......... .......... .......... .......... 28%  193M 0s\n","  6100K .......... .......... .......... .......... .......... 29%  239M 0s\n","  6150K .......... .......... .......... .......... .......... 29%  183M 0s\n","  6200K .......... .......... .......... .......... .......... 29% 44.2M 0s\n","  6250K .......... .......... .......... .......... .......... 29% 35.6M 0s\n","  6300K .......... .......... .......... .......... .......... 30% 49.1M 0s\n","  6350K .......... .......... .......... .......... .......... 30% 43.7M 0s\n","  6400K .......... .......... .......... .......... .......... 30% 46.9M 0s\n","  6450K .......... .......... .......... .......... .......... 30% 35.3M 0s\n","  6500K .......... .......... .......... .......... .......... 31% 48.2M 0s\n","  6550K .......... .......... .......... .......... .......... 31% 44.2M 0s\n","  6600K .......... .......... .......... .......... .......... 31% 46.8M 0s\n","  6650K .......... .......... .......... .......... .......... 31% 40.3M 0s\n","  6700K .......... .......... .......... .......... .......... 32% 34.2M 0s\n","  6750K .......... .......... .......... .......... .......... 32% 46.2M 0s\n","  6800K .......... .......... .......... .......... .......... 32% 36.9M 0s\n","  6850K .......... .......... .......... .......... .......... 32% 37.5M 0s\n","  6900K .......... .......... .......... .......... .......... 32% 44.7M 0s\n","  6950K .......... .......... .......... .......... .......... 33% 55.7M 0s\n","  7000K .......... .......... .......... .......... .......... 33%  228M 0s\n","  7050K .......... .......... .......... .......... .......... 33%  212M 0s\n","  7100K .......... .......... .......... .......... .......... 33%  217M 0s\n","  7150K .......... .......... .......... .......... .......... 34%  246M 0s\n","  7200K .......... .......... .......... .......... .......... 34%  256M 0s\n","  7250K .......... .......... .......... .......... .......... 34%  207M 0s\n","  7300K .......... .......... .......... .......... .......... 34%  222M 0s\n","  7350K .......... .......... .......... .......... .......... 35%  229M 0s\n","  7400K .......... .......... .......... .......... .......... 35%  250M 0s\n","  7450K .......... .......... .......... .......... .......... 35%  215M 0s\n","  7500K .......... .......... .......... .......... .......... 35%  251M 0s\n","  7550K .......... .......... .......... .......... .......... 36%  215M 0s\n","  7600K .......... .......... .......... .......... .......... 36%  238M 0s\n","  7650K .......... .......... .......... .......... .......... 36%  202M 0s\n","  7700K .......... .......... .......... .......... .......... 36%  242M 0s\n","  7750K .......... .......... .......... .......... .......... 36%  247M 0s\n","  7800K .......... .......... .......... .......... .......... 37%  138M 0s\n","  7850K .......... .......... .......... .......... .......... 37%  193M 0s\n","  7900K .......... .......... .......... .......... .......... 37%  170M 0s\n","  7950K .......... .......... .......... .......... .......... 37% 70.9M 0s\n","  8000K .......... .......... .......... .......... .......... 38% 43.5M 0s\n","  8050K .......... .......... .......... .......... .......... 38% 35.9M 0s\n","  8100K .......... .......... .......... .......... .......... 38% 40.5M 0s\n","  8150K .......... .......... .......... .......... .......... 38% 44.1M 0s\n","  8200K .......... .......... .......... .......... .......... 39% 46.2M 0s\n","  8250K .......... .......... .......... .......... .......... 39% 40.7M 0s\n","  8300K .......... .......... .......... .......... .......... 39% 46.2M 0s\n","  8350K .......... .......... .......... .......... .......... 39% 45.1M 0s\n","  8400K .......... .......... .......... .......... .......... 40% 35.9M 0s\n","  8450K .......... .......... .......... .......... .......... 40% 36.0M 0s\n","  8500K .......... .......... .......... .......... .......... 40% 43.1M 0s\n","  8550K .......... .......... .......... .......... .......... 40% 39.6M 0s\n","  8600K .......... .......... .......... .......... .......... 41% 43.1M 0s\n","  8650K .......... .......... .......... .......... .......... 41% 40.0M 0s\n","  8700K .......... .......... .......... .......... .......... 41% 25.2M 0s\n","  8750K .......... .......... .......... .......... .......... 41% 67.4M 0s\n","  8800K .......... .......... .......... .......... .......... 41%  110M 0s\n","  8850K .......... .......... .......... .......... .......... 42% 31.5M 0s\n","  8900K .......... .......... .......... .......... .......... 42%  233M 0s\n","  8950K .......... .......... .......... .......... .......... 42% 40.5M 0s\n","  9000K .......... .......... .......... .......... .......... 42%  101M 0s\n","  9050K .......... .......... .......... .......... .......... 43%  216M 0s\n","  9100K .......... .......... .......... .......... .......... 43%  218M 0s\n","  9150K .......... .......... .......... .......... .......... 43%  223M 0s\n","  9200K .......... .......... .......... .......... .......... 43%  241M 0s\n","  9250K .......... .......... .......... .......... .......... 44%  210M 0s\n","  9300K .......... .......... .......... .......... .......... 44%  176M 0s\n","  9350K .......... .......... .......... .......... .......... 44%  271M 0s\n","  9400K .......... .......... .......... .......... .......... 44%  253M 0s\n","  9450K .......... .......... .......... .......... .......... 45%  219M 0s\n","  9500K .......... .......... .......... .......... .......... 45%  254M 0s\n","  9550K .......... .......... .......... .......... .......... 45%  230M 0s\n","  9600K .......... .......... .......... .......... .......... 45%  239M 0s\n","  9650K .......... .......... .......... .......... .......... 45%  142M 0s\n","  9700K .......... .......... .......... .......... .......... 46%  231M 0s\n","  9750K .......... .......... .......... .......... .......... 46%  221M 0s\n","  9800K .......... .......... .......... .......... .......... 46%  245M 0s\n","  9850K .......... .......... .......... .......... .......... 46%  217M 0s\n","  9900K .......... .......... .......... .......... .......... 47%  265M 0s\n","  9950K .......... .......... .......... .......... .......... 47%  251M 0s\n"," 10000K .......... .......... .......... .......... .......... 47% 71.9M 0s\n"," 10050K .......... .......... .......... .......... .......... 47% 40.7M 0s\n"," 10100K .......... .......... .......... .......... .......... 48% 46.7M 0s\n"," 10150K .......... .......... .......... .......... .......... 48% 38.1M 0s\n"," 10200K .......... .......... .......... .......... .......... 48% 43.5M 0s\n"," 10250K .......... .......... .......... .......... .......... 48% 39.0M 0s\n"," 10300K .......... .......... .......... .......... .......... 49% 42.4M 0s\n"," 10350K .......... .......... .......... .......... .......... 49% 43.2M 0s\n"," 10400K .......... .......... .......... .......... .......... 49% 41.4M 0s\n"," 10450K .......... .......... .......... .......... .......... 49% 40.8M 0s\n"," 10500K .......... .......... .......... .......... .......... 50% 47.6M 0s\n"," 10550K .......... .......... .......... .......... .......... 50% 44.7M 0s\n"," 10600K .......... .......... .......... .......... .......... 50% 34.2M 0s\n"," 10650K .......... .......... .......... .......... .......... 50% 32.8M 0s\n"," 10700K .......... .......... .......... .......... .......... 50% 35.5M 0s\n"," 10750K .......... .......... .......... .......... .......... 51% 38.2M 0s\n"," 10800K .......... .......... .......... .......... .......... 51% 41.2M 0s\n"," 10850K .......... .......... .......... .......... .......... 51% 61.3M 0s\n"," 10900K .......... .......... .......... .......... .......... 51% 70.5M 0s\n"," 10950K .......... .......... .......... .......... .......... 52% 82.2M 0s\n"," 11000K .......... .......... .......... .......... .......... 52%  225M 0s\n"," 11050K .......... .......... .......... .......... .......... 52%  201M 0s\n"," 11100K .......... .......... .......... .......... .......... 52%  245M 0s\n"," 11150K .......... .......... .......... .......... .......... 53%  241M 0s\n"," 11200K .......... .......... .......... .......... .......... 53%  215M 0s\n"," 11250K .......... .......... .......... .......... .......... 53%  192M 0s\n"," 11300K .......... .......... .......... .......... .......... 53%  250M 0s\n"," 11350K .......... .......... .......... .......... .......... 54%  239M 0s\n"," 11400K .......... .......... .......... .......... .......... 54%  230M 0s\n"," 11450K .......... .......... .......... .......... .......... 54%  195M 0s\n"," 11500K .......... .......... .......... .......... .......... 54%  139M 0s\n"," 11550K .......... .......... .......... .......... .......... 54%  236M 0s\n"," 11600K .......... .......... .......... .......... .......... 55%  222M 0s\n"," 11650K .......... .......... .......... .......... .......... 55%  132M 0s\n"," 11700K .......... .......... .......... .......... .......... 55%  251M 0s\n"," 11750K .......... .......... .......... .......... .......... 55%  226M 0s\n"," 11800K .......... .......... .......... .......... .......... 56% 89.0M 0s\n"," 11850K .......... .......... .......... .......... .......... 56% 40.0M 0s\n"," 11900K .......... .......... .......... .......... .......... 56% 41.3M 0s\n"," 11950K .......... .......... .......... .......... .......... 56% 45.7M 0s\n"," 12000K .......... .......... .......... .......... .......... 57% 47.2M 0s\n"," 12050K .......... .......... .......... .......... .......... 57% 43.5M 0s\n"," 12100K .......... .......... .......... .......... .......... 57% 47.7M 0s\n"," 12150K .......... .......... .......... .......... .......... 57% 45.1M 0s\n"," 12200K .......... .......... .......... .......... .......... 58% 38.5M 0s\n"," 12250K .......... .......... .......... .......... .......... 58% 34.1M 0s\n"," 12300K .......... .......... .......... .......... .......... 58% 44.0M 0s\n"," 12350K .......... .......... .......... .......... .......... 58% 37.5M 0s\n"," 12400K .......... .......... .......... .......... .......... 59% 44.5M 0s\n"," 12450K .......... .......... .......... .......... .......... 59% 37.4M 0s\n"," 12500K .......... .......... .......... .......... .......... 59% 46.1M 0s\n"," 12550K .......... .......... .......... .......... .......... 59%  126M 0s\n"," 12600K .......... .......... .......... .......... .......... 59%  230M 0s\n"," 12650K .......... .......... .......... .......... .......... 60%  206M 0s\n"," 12700K .......... .......... .......... .......... .......... 60%  247M 0s\n"," 12750K .......... .......... .......... .......... .......... 60%  241M 0s\n"," 12800K .......... .......... .......... .......... .......... 60%  215M 0s\n"," 12850K .......... .......... .......... .......... .......... 61%  172M 0s\n"," 12900K .......... .......... .......... .......... .......... 61%  240M 0s\n"," 12950K .......... .......... .......... .......... .......... 61%  241M 0s\n"," 13000K .......... .......... .......... .......... .......... 61% 42.3M 0s\n"," 13050K .......... .......... .......... .......... .......... 62% 29.3M 0s\n"," 13100K .......... .......... .......... .......... .......... 62% 26.1M 0s\n"," 13150K .......... .......... .......... .......... .......... 62% 34.6M 0s\n"," 13200K .......... .......... .......... .......... .......... 62% 42.3M 0s\n"," 13250K .......... .......... .......... .......... .......... 63% 38.4M 0s\n"," 13300K .......... .......... .......... .......... .......... 63% 45.4M 0s\n"," 13350K .......... .......... .......... .......... .......... 63% 29.3M 0s\n"," 13400K .......... .......... .......... .......... .......... 63% 52.6M 0s\n"," 13450K .......... .......... .......... .......... .......... 64% 70.4M 0s\n"," 13500K .......... .......... .......... .......... .......... 64%  176M 0s\n"," 13550K .......... .......... .......... .......... .......... 64%  218M 0s\n"," 13600K .......... .......... .......... .......... .......... 64%  225M 0s\n"," 13650K .......... .......... .......... .......... .......... 64%  183M 0s\n"," 13700K .......... .......... .......... .......... .......... 65%  215M 0s\n"," 13750K .......... .......... .......... .......... .......... 65%  195M 0s\n"," 13800K .......... .......... .......... .......... .......... 65%  180M 0s\n"," 13850K .......... .......... .......... .......... .......... 65%  193M 0s\n"," 13900K .......... .......... .......... .......... .......... 66%  217M 0s\n"," 13950K .......... .......... .......... .......... .......... 66%  203M 0s\n"," 14000K .......... .......... .......... .......... .......... 66%  208M 0s\n"," 14050K .......... .......... .......... .......... .......... 66%  187M 0s\n"," 14100K .......... .......... .......... .......... .......... 67%  261M 0s\n"," 14150K .......... .......... .......... .......... .......... 67%  244M 0s\n"," 14200K .......... .......... .......... .......... .......... 67%  264M 0s\n"," 14250K .......... .......... .......... .......... .......... 67%  237M 0s\n"," 14300K .......... .......... .......... .......... .......... 68%  265M 0s\n"," 14350K .......... .......... .......... .......... .......... 68%  219M 0s\n"," 14400K .......... .......... .......... .......... .......... 68%  248M 0s\n"," 14450K .......... .......... .......... .......... .......... 68%  220M 0s\n"," 14500K .......... .......... .......... .......... .......... 68%  270M 0s\n"," 14550K .......... .......... .......... .......... .......... 69%  236M 0s\n"," 14600K .......... .......... .......... .......... .......... 69%  196M 0s\n"," 14650K .......... .......... .......... .......... .......... 69%  182M 0s\n"," 14700K .......... .......... .......... .......... .......... 69%  217M 0s\n"," 14750K .......... .......... .......... .......... .......... 70%  221M 0s\n"," 14800K .......... .......... .......... .......... .......... 70%  220M 0s\n"," 14850K .......... .......... .......... .......... .......... 70%  174M 0s\n"," 14900K .......... .......... .......... .......... .......... 70%  201M 0s\n"," 14950K .......... .......... .......... .......... .......... 71%  223M 0s\n"," 15000K .......... .......... .......... .......... .......... 71%  220M 0s\n"," 15050K .......... .......... .......... .......... .......... 71%  186M 0s\n"," 15100K .......... .......... .......... .......... .......... 71%  219M 0s\n"," 15150K .......... .......... .......... .......... .......... 72%  223M 0s\n"," 15200K .......... .......... .......... .......... .......... 72%  226M 0s\n"," 15250K .......... .......... .......... .......... .......... 72%  173M 0s\n"," 15300K .......... .......... .......... .......... .......... 72%  218M 0s\n"," 15350K .......... .......... .......... .......... .......... 73%  224M 0s\n"," 15400K .......... .......... .......... .......... .......... 73%  203M 0s\n"," 15450K .......... .......... .......... .......... .......... 73%  195M 0s\n"," 15500K .......... .......... .......... .......... .......... 73%  192M 0s\n"," 15550K .......... .......... .......... .......... .......... 73%  230M 0s\n"," 15600K .......... .......... .......... .......... .......... 74%  226M 0s\n"," 15650K .......... .......... .......... .......... .......... 74%  166M 0s\n"," 15700K .......... .......... .......... .......... .......... 74%  181M 0s\n"," 15750K .......... .......... .......... .......... .......... 74%  215M 0s\n"," 15800K .......... .......... .......... .......... .......... 75%  222M 0s\n"," 15850K .......... .......... .......... .......... .......... 75%  189M 0s\n"," 15900K .......... .......... .......... .......... .......... 75%  196M 0s\n"," 15950K .......... .......... .......... .......... .......... 75%  208M 0s\n"," 16000K .......... .......... .......... .......... .......... 76%  221M 0s\n"," 16050K .......... .......... .......... .......... .......... 76%  168M 0s\n"," 16100K .......... .......... .......... .......... .......... 76%  152M 0s\n"," 16150K .......... .......... .......... .......... .......... 76%  217M 0s\n"," 16200K .......... .......... .......... .......... .......... 77%  212M 0s\n"," 16250K .......... .......... .......... .......... .......... 77%  221M 0s\n"," 16300K .......... .......... .......... .......... .......... 77%  231M 0s\n"," 16350K .......... .......... .......... .......... .......... 77%  278M 0s\n"," 16400K .......... .......... .......... .......... .......... 77%  270M 0s\n"," 16450K .......... .......... .......... .......... .......... 78%  229M 0s\n"," 16500K .......... .......... .......... .......... .......... 78%  255M 0s\n"," 16550K .......... .......... .......... .......... .......... 78%  250M 0s\n"," 16600K .......... .......... .......... .......... .......... 78%  269M 0s\n"," 16650K .......... .......... .......... .......... .......... 79%  229M 0s\n"," 16700K .......... .......... .......... .......... .......... 79%  220M 0s\n"," 16750K .......... .......... .......... .......... .......... 79%  240M 0s\n"," 16800K .......... .......... .......... .......... .......... 79%  206M 0s\n"," 16850K .......... .......... .......... .......... .......... 80%  213M 0s\n"," 16900K .......... .......... .......... .......... .......... 80%  246M 0s\n"," 16950K .......... .......... .......... .......... .......... 80%  253M 0s\n"," 17000K .......... .......... .......... .......... .......... 80%  237M 0s\n"," 17050K .......... .......... .......... .......... .......... 81%  181M 0s\n"," 17100K .......... .......... .......... .......... .......... 81%  227M 0s\n"," 17150K .......... .......... .......... .......... .......... 81%  221M 0s\n"," 17200K .......... .......... .......... .......... .......... 81%  226M 0s\n"," 17250K .......... .......... .......... .......... .......... 82%  102M 0s\n"," 17300K .......... .......... .......... .......... .......... 82%  200M 0s\n"," 17350K .......... .......... .......... .......... .......... 82%  221M 0s\n"," 17400K .......... .......... .......... .......... .......... 82%  174M 0s\n"," 17450K .......... .......... .......... .......... .......... 82%  195M 0s\n"," 17500K .......... .......... .......... .......... .......... 83%  214M 0s\n"," 17550K .......... .......... .......... .......... .......... 83%  221M 0s\n"," 17600K .......... .......... .......... .......... .......... 83%  205M 0s\n"," 17650K .......... .......... .......... .......... .......... 83%  172M 0s\n"," 17700K .......... .......... .......... .......... .......... 84%  179M 0s\n"," 17750K .......... .......... .......... .......... .......... 84%  195M 0s\n"," 17800K .......... .......... .......... .......... .......... 84%  207M 0s\n"," 17850K .......... .......... .......... .......... .......... 84%  200M 0s\n"," 17900K .......... .......... .......... .......... .......... 85%  174M 0s\n"," 17950K .......... .......... .......... .......... .......... 85%  205M 0s\n"," 18000K .......... .......... .......... .......... .......... 85%  207M 0s\n"," 18050K .......... .......... .......... .......... .......... 85%  179M 0s\n"," 18100K .......... .......... .......... .......... .......... 86%  216M 0s\n"," 18150K .......... .......... .......... .......... .......... 86%  212M 0s\n"," 18200K .......... .......... .......... .......... .......... 86%  193M 0s\n"," 18250K .......... .......... .......... .......... .......... 86%  177M 0s\n"," 18300K .......... .......... .......... .......... .......... 87%  181M 0s\n"," 18350K .......... .......... .......... .......... .......... 87%  201M 0s\n"," 18400K .......... .......... .......... .......... .......... 87%  201M 0s\n"," 18450K .......... .......... .......... .......... .......... 87%  170M 0s\n"," 18500K .......... .......... .......... .......... .......... 87%  187M 0s\n"," 18550K .......... .......... .......... .......... .......... 88%  209M 0s\n"," 18600K .......... .......... .......... .......... .......... 88%  194M 0s\n"," 18650K .......... .......... .......... .......... .......... 88%  196M 0s\n"," 18700K .......... .......... .......... .......... .......... 88%  213M 0s\n"," 18750K .......... .......... .......... .......... .......... 89%  221M 0s\n"," 18800K .......... .......... .......... .......... .......... 89%  172M 0s\n"," 18850K .......... .......... .......... .......... .......... 89%  176M 0s\n"," 18900K .......... .......... .......... .......... .......... 89%  215M 0s\n"," 18950K .......... .......... .......... .......... .......... 90%  215M 0s\n"," 19000K .......... .......... .......... .......... .......... 90%  209M 0s\n"," 19050K .......... .......... .......... .......... .......... 90%  182M 0s\n"," 19100K .......... .......... .......... .......... .......... 90%  212M 0s\n"," 19150K .......... .......... .......... .......... .......... 91%  215M 0s\n"," 19200K .......... .......... .......... .......... .......... 91%  201M 0s\n"," 19250K .......... .......... .......... .......... .......... 91%  185M 0s\n"," 19300K .......... .......... .......... .......... .......... 91%  209M 0s\n"," 19350K .......... .......... .......... .......... .......... 91%  222M 0s\n"," 19400K .......... .......... .......... .......... .......... 92%  209M 0s\n"," 19450K .......... .......... .......... .......... .......... 92%  202M 0s\n"," 19500K .......... .......... .......... .......... .......... 92%  225M 0s\n"," 19550K .......... .......... .......... .......... .......... 92%  229M 0s\n"," 19600K .......... .......... .......... .......... .......... 93%  222M 0s\n"," 19650K .......... .......... .......... .......... .......... 93%  178M 0s\n"," 19700K .......... .......... .......... .......... .......... 93%  204M 0s\n"," 19750K .......... .......... .......... .......... .......... 93%  222M 0s\n"," 19800K .......... .......... .......... .......... .......... 94%  180M 0s\n"," 19850K .......... .......... .......... .......... .......... 94%  156M 0s\n"," 19900K .......... .......... .......... .......... .......... 94%  208M 0s\n"," 19950K .......... .......... .......... .......... .......... 94%  218M 0s\n"," 20000K .......... .......... .......... .......... .......... 95%  209M 0s\n"," 20050K .......... .......... .......... .......... .......... 95%  177M 0s\n"," 20100K .......... .......... .......... .......... .......... 95%  220M 0s\n"," 20150K .......... .......... .......... .......... .......... 95%  208M 0s\n"," 20200K .......... .......... .......... .......... .......... 96%  218M 0s\n"," 20250K .......... .......... .......... .......... .......... 96%  182M 0s\n"," 20300K .......... .......... .......... .......... .......... 96%  219M 0s\n"," 20350K .......... .......... .......... .......... .......... 96%  210M 0s\n"," 20400K .......... .......... .......... .......... .......... 96%  216M 0s\n"," 20450K .......... .......... .......... .......... .......... 97%  159M 0s\n"," 20500K .......... .......... .......... .......... .......... 97%  231M 0s\n"," 20550K .......... .......... .......... .......... .......... 97%  227M 0s\n"," 20600K .......... .......... .......... .......... .......... 97%  227M 0s\n"," 20650K .......... .......... .......... .......... .......... 98%  184M 0s\n"," 20700K .......... .......... .......... .......... .......... 98%  227M 0s\n"," 20750K .......... .......... .......... .......... .......... 98%  226M 0s\n"," 20800K .......... .......... .......... .......... .......... 98%  230M 0s\n"," 20850K .......... .......... .......... .......... .......... 99%  173M 0s\n"," 20900K .......... .......... .......... .......... .......... 99%  198M 0s\n"," 20950K .......... .......... .......... .......... .......... 99%  220M 0s\n"," 21000K .......... .......... .......... .......... .......... 99%  223M 0s\n"," 21050K .......... .......... .......... ..........           100%  222M=0.3s\n","\n","2022-10-30 23:46:48 (77.1 MB/s) - ‘imdb_reviews_preprocessed.parquet’ saved [21597134/21597134]\n","\n","--2022-10-30 23:46:48--  https://raw.githubusercontent.com/wewilli1/ist718_data/master/sentiments.parquet\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 56439 (55K) [application/octet-stream]\n","Saving to: ‘sentiments.parquet’\n","\n","     0K .......... .......... .......... .......... .......... 90% 4.76M 0s\n","    50K .....                                                 100% 6.43M=0.01s\n","\n","2022-10-30 23:46:48 (4.88 MB/s) - ‘sentiments.parquet’ saved [56439/56439]\n","\n","--2022-10-30 23:46:48--  https://raw.githubusercontent.com/wewilli1/ist718_data/master/tweets.parquet\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 154653 (151K) [application/octet-stream]\n","Saving to: ‘tweets.parquet’\n","\n","     0K .......... .......... .......... .......... .......... 33% 4.30M 0s\n","    50K .......... .......... .......... .......... .......... 66% 5.15M 0s\n","   100K .......... .......... .......... .......... .......... 99% 25.0M 0s\n","   150K .                                                     100% 1961G=0.02s\n","\n","2022-10-30 23:46:49 (6.47 MB/s) - ‘tweets.parquet’ saved [154653/154653]\n","\n"]}],"source":["%%bash\n","\n","# Download the data files from github\n","\n","data_file_1=imdb_reviews_preprocessed.parquet\n","data_file_2=sentiments.parquet\n","data_file_3=tweets.parquet\n","\n","# If data_file_1 file does not exist in the colab environment\n","if [[ ! -f ${data_file_1} ]]; then \n","   # download the data file from github and save it in this colab environment instance\n","   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/${data_file_1} \n","fi\n","\n","# If data_file_1 file does not exist in the colab environment\n","if [[ ! -f ${data_file_2} ]]; then \n","   # download the data file from github and save it in this colab environment instance\n","   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/${data_file_2} \n","fi\n","\n","# If data_file_1 file does not exist in the colab environment\n","if [[ ! -f ${data_file_3} ]]; then \n","   # download the data file from github and save it in this colab environment instance\n","   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/${data_file_3} \n","fi"]},{"cell_type":"markdown","metadata":{"id":"YeTwsoOCxIRW"},"source":["# Spark ML"]},{"cell_type":"markdown","metadata":{"id":"Is9JuaDOxIRX"},"source":["In previous versions of Spark, most Machine Learning funcionality was provided through RDD (Resilient Distributed Datasets). However, to improve performance and communicability of results, Spark developers ported the ML functionality to work almost exclusively with DataFrames. Future releases of Spark will not update the support of ML with RDDs.\n","\n","In this modern Spark ML approach, there are _Estimators_ and _Transformers_. Estimators have some parameters that need to be fit into the data. After fitting, Estimators return Transformers. Tranformers can be applied to dataframes, taking one (or several) columns as input and creating none (or several) columns as output.\n","\n","A _Pipeline_ combines several _Tranformers_ with a final _Estimator_. The _Pipeline_, therefore, can be fit to the data because the final step of the process (the _Estimator_) is fit to the data. The result of the fitting is a pipelined _Transformer_ that takes an input dataframe through all the stages of the Pipeline.\n","\n","There is a third type of functionality that allows to select features."]},{"cell_type":"markdown","metadata":{"id":"nUZsM6sWxIRZ"},"source":["For example, for analyzing text, a typical pipelined estimator is as follows:\n","\n","<img src=\"http://spark.apache.org/docs/latest/img/ml-Pipeline.png\" alt=\"ML Pipeline\" style=\"width: 100%;\"/>"]},{"cell_type":"markdown","metadata":{"id":"ihV9U056xIRa"},"source":["After fitting, the Pipeline becomes a transformer:\n","\n","<img src=\"http://spark.apache.org/docs/latest/img/ml-PipelineModel.png\" alt=\"ML Model\" style=\"width: 100%;\"/>\n","(Images from http://spark.apache.org/docs/latest/ml-pipeline.html)"]},{"cell_type":"markdown","metadata":{"id":"hTYv4KnRxIRa"},"source":["Importantly, transformers can be saved and exchanged with other data scientists, improving reproducibility."]},{"cell_type":"markdown","metadata":{"id":"eVwKoZkJxIRb"},"source":["## Loading packages and connecting to Spark cluster"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"FRC9edfXxIRd","executionInfo":{"status":"ok","timestamp":1667173621201,"user_tz":240,"elapsed":11797,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from __future__ import division\n","from pyspark.sql import SparkSession\n","from pyspark.ml import feature, regression, evaluation, Pipeline\n","from pyspark.sql import functions as fn, Row\n","import matplotlib.pyplot as plt\n","import glob\n","import subprocess\n","import numpy as np\n","import pandas as pd\n","import os\n","spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext"]},{"cell_type":"markdown","metadata":{"id":"IDDjxnJWxIRi"},"source":["### Transformers and Estimators"]},{"cell_type":"markdown","metadata":{"id":"KsCEBcmlxIRj"},"source":["Let's define an example dataframe with documents"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":14635,"status":"ok","timestamp":1667173635832,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"41XGfvHwxIRj","outputId":"8dc0461a-aa48-444d-aab8-e28aaee12fa6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   doc_id                text  user_id\n","0       1  cats cats are cute        0\n","1       2   dogs are playfull        0\n","2       3       lions are big        1\n","3       4       cars are fast        1"],"text/html":["\n","  <div id=\"df-835f129d-3ab2-4d15-ad6d-2f9119a82358\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>doc_id</th>\n","      <th>text</th>\n","      <th>user_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>cats cats are cute</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>dogs are playfull</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>lions are big</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>cars are fast</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-835f129d-3ab2-4d15-ad6d-2f9119a82358')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-835f129d-3ab2-4d15-ad6d-2f9119a82358 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-835f129d-3ab2-4d15-ad6d-2f9119a82358');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["documents_df = spark.sparkContext.parallelize([\n","        [1, 'cats cats are cute', 0],\n","        [2, 'dogs are playfull', 0],\n","        [3, 'lions are big', 1],\n","        [4, 'cars are fast', 1]]).toDF(['doc_id', 'text', 'user_id'])\n","documents_df.toPandas()"]},{"cell_type":"markdown","metadata":{"id":"S0b6yxvSxIRk"},"source":["There are several ways of transforming the data from raw input to something that can be analyzed with a statistical model.\n","\n","Some examples of such transformers are displayed below:\n","\n","#### Tokenizer\n","\n","Suppose that we want to split the document into separate words where each word is a _token_. This is what `Tokenizer` does."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ouI7ZvtFxIRl","executionInfo":{"status":"ok","timestamp":1667173635833,"user_tz":240,"elapsed":6,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.feature import Tokenizer"]},{"cell_type":"markdown","metadata":{"id":"VNIT9hrwxIRl"},"source":["Almost all transfomers and estimators require you to specificy the input column of the dataframe and the output column that will be added to the dataframe."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"t8yaModZxIRm","executionInfo":{"status":"ok","timestamp":1667173636021,"user_tz":240,"elapsed":3,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["# the tokenizer object\n","tokenizer = Tokenizer().setInputCol('text').setOutputCol('words')"]},{"cell_type":"markdown","metadata":{"id":"HYTOzECbxIRm"},"source":["We can now transform the dataframe"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2612,"status":"ok","timestamp":1667173638631,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"wyOucZywxIRm","outputId":"b32da8c9-bf53-4ae0-a811-442296eb0ffd","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["+------+------------------+-------+--------------------+\n","|doc_id|              text|user_id|               words|\n","+------+------------------+-------+--------------------+\n","|     1|cats cats are cute|      0|[cats, cats, are,...|\n","|     2| dogs are playfull|      0|[dogs, are, playf...|\n","|     3|     lions are big|      1|   [lions, are, big]|\n","|     4|     cars are fast|      1|   [cars, are, fast]|\n","+------+------------------+-------+--------------------+\n","\n"]}],"source":["tokenizer.transform(documents_df).show()"]},{"cell_type":"markdown","metadata":{"id":"RT2zxkhVxIRn"},"source":["#### CountVectorizer"]},{"cell_type":"markdown","metadata":{"id":"JaIemoSNxIRn"},"source":["This transformer counts how many times a word appears in a list and produces a vector with such counts. This is very useful for text analysis."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"IJpFX41hxIRn","executionInfo":{"status":"ok","timestamp":1667173638632,"user_tz":240,"elapsed":5,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.feature import CountVectorizer"]},{"cell_type":"markdown","metadata":{"id":"DZrFgEIJxIRo"},"source":["A `CountVectorizer` is different from a `Tokenizer` because it needs to learn how many different tokens there are in the input column. With that number, it will output vectors with consistent dimensions. Therefore, `CountVectorizer` is an `Estimator` that, when fitted, returns a `Transformer`."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"J--0hoXrxIRo","executionInfo":{"status":"ok","timestamp":1667173638632,"user_tz":240,"elapsed":4,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["count_vectorizer_estimator = CountVectorizer().setInputCol('words').setOutputCol('features')"]},{"cell_type":"markdown","metadata":{"id":"dDuJ_UoFxIRo"},"source":["Now we need to use the words column that was generated by the `tokenizer` transformer"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1140,"status":"ok","timestamp":1667173639769,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"-vwhsDFvxIRo","outputId":"4c4feb61-f3b4-4303-bfee-524436d46df8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['are', 'cats', 'fast', 'playfull', 'big', 'dogs', 'lions', 'cute', 'cars']"]},"metadata":{},"execution_count":10}],"source":["count_vectorizer_transformer = count_vectorizer_estimator.fit(tokenizer.transform(documents_df))\n","count_vectorizer_transformer.vocabulary"]},{"cell_type":"markdown","metadata":{"id":"WWgn_xSyxIRp"},"source":["which results in:"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":763,"status":"ok","timestamp":1667173640704,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"8ZcdBsadxIRp","outputId":"0b48514d-3886-4f2e-a0ef-d09b6de5887e","scrolled":false},"outputs":[{"output_type":"stream","name":"stdout","text":["+------+------------------+-------+-----------------------+-------------------------+\n","|doc_id|text              |user_id|words                  |features                 |\n","+------+------------------+-------+-----------------------+-------------------------+\n","|1     |cats cats are cute|0      |[cats, cats, are, cute]|(9,[0,1,7],[1.0,2.0,1.0])|\n","|2     |dogs are playfull |0      |[dogs, are, playfull]  |(9,[0,3,5],[1.0,1.0,1.0])|\n","|3     |lions are big     |1      |[lions, are, big]      |(9,[0,4,6],[1.0,1.0,1.0])|\n","|4     |cars are fast     |1      |[cars, are, fast]      |(9,[0,2,8],[1.0,1.0,1.0])|\n","+------+------------------+-------+-----------------------+-------------------------+\n","\n"]}],"source":["count_vectorizer_transformer.transform(tokenizer.transform(documents_df)).show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"1_Gt28LbxIRp"},"source":["In the cell below, we transform using a new dataframe which has an unseen word `lizard`.  Notice that lizard does not appear in the vocabulary that was present during the fit operation above.  Since lizard is not included in the vocabulary, the features column in row 1 does not include lizard in the features.  In fact, the features col of row 1 indicates that only 2 words are present when in fact there is 3 words present.  There are only 2 words present in the features column because the word `lizard` was not present during the fit operation.  This allows us to train a model and then make predictions on unseen data that might contain some words that were not present during the fit process.  In this notebook, we will train a model using IMDB movie data and then make predictions on tweets from the 2016 election using the same model trained on IMDB data.  "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":728,"status":"ok","timestamp":1667173641430,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"huTmzVLCxIRp","outputId":"d6e44232-87d7-4047-dbcd-bc73befdf4c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------+-----------------+-------+---------------------+-------------------------+\n","|doc_id|text             |user_id|words                |features                 |\n","+------+-----------------+-------+---------------------+-------------------------+\n","|1     |lizards are cute |0      |[lizards, are, cute] |(9,[0,7],[1.0,1.0])      |\n","|2     |dogs are playfull|0      |[dogs, are, playfull]|(9,[0,3,5],[1.0,1.0,1.0])|\n","|3     |lions are big    |1      |[lions, are, big]    |(9,[0,4,6],[1.0,1.0,1.0])|\n","|4     |cars are fast    |1      |[cars, are, fast]    |(9,[0,2,8],[1.0,1.0,1.0])|\n","+------+-----------------+-------+---------------------+-------------------------+\n","\n","['are', 'cats', 'fast', 'playfull', 'big', 'dogs', 'lions', 'cute', 'cars']\n"]}],"source":["# create a new dataframe that contains an unseen word 'lizard'\n","documents_df1 = spark.sparkContext.parallelize([\n","        [1, 'lizards are cute', 0],\n","        [2, 'dogs are playfull', 0],\n","        [3, 'lions are big', 1],\n","        [4, 'cars are fast', 1]]).toDF(['doc_id', 'text', 'user_id'])\n","\n","# transform the new dataframe and notice that lizard is not in the feature data\n","count_vectorizer_transformer.transform(tokenizer.transform(documents_df1)).show(truncate=False)\n","\n","# print the vocabulary created during the fit process, notice that lizard is not present\n","print(count_vectorizer_transformer.vocabulary)"]},{"cell_type":"markdown","metadata":{"id":"-JGBNM2fxIRq"},"source":["The column `features` is a sparse vector representation. For example, assume that the first document (document id 1) has the following features: \n","\n","(9,[0,1,6],[1.0,2.0,1.0]) \n","\n","The '9' indicates that there are a total of 9 features or words.\n","\n","The \\[0,1,6] indicates that the words in this document correspond to vocabulary indices (see vocabulary below) 0, 1, and 6.  Note that this mapping can change from run to run.  By looking at the vocabulary learned by `count_vectorizer_transformer`, we can look up which words those feature indices refer to.\n","\n","The \\[1.0,2.0,1.0] indicates the count of each word in the document."]},{"cell_type":"markdown","metadata":{"id":"ovZasbZ3xIRq"},"source":["## Pipelines\n","\n","Sometimes, we have long preprocessing steps that take raw data and transform it through several stages. As explained before, these complex transformations can be captured by Pipelines.\n","\n","Pipelines are always estimators, even when they contain several transformers. After a pipeline is `fit` to the data, the pipeline becomes a transformer.\n","\n","We will now define a pipeline that takes the raw `text` column and produces the `features` column previously explained"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xj11ADjrxIRr","executionInfo":{"status":"ok","timestamp":1667173641431,"user_tz":240,"elapsed":4,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml import Pipeline"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"nNA9cMwgxIRr","executionInfo":{"status":"ok","timestamp":1667173641431,"user_tz":240,"elapsed":3,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["pipeline_cv_estimator = Pipeline(stages=[tokenizer, count_vectorizer_estimator])"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"H4AzBkTAxIRs","executionInfo":{"status":"ok","timestamp":1667173641864,"user_tz":240,"elapsed":436,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["pipeline_cv_transformer = pipeline_cv_estimator.fit(documents_df)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":486,"status":"ok","timestamp":1667173642348,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"CmEd191KxIRs","outputId":"6884917e-bafa-402b-f30a-6e25b14076be"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------+------------------+-------+--------------------+--------------------+\n","|doc_id|              text|user_id|               words|            features|\n","+------+------------------+-------+--------------------+--------------------+\n","|     1|cats cats are cute|      0|[cats, cats, are,...|(9,[0,1,4],[1.0,2...|\n","|     2| dogs are playfull|      0|[dogs, are, playf...|(9,[0,2,6],[1.0,1...|\n","|     3|     lions are big|      1|   [lions, are, big]|(9,[0,3,5],[1.0,1...|\n","|     4|     cars are fast|      1|   [cars, are, fast]|(9,[0,7,8],[1.0,1...|\n","+------+------------------+-------+--------------------+--------------------+\n","\n"]}],"source":["pipeline_cv_transformer.transform(documents_df).show()"]},{"cell_type":"markdown","metadata":{"id":"RHMwuXXExIRt"},"source":["In more complex scenarios, you can even chain Pipeline transformers. We will see this case in the actual use case below.\n","\n","For a more detail explanation of Pipelines, Estimators, and Transformers, [see here](http://spark.apache.org/docs/latest/ml-pipeline.html)"]},{"cell_type":"markdown","metadata":{"id":"Lcqun_G7xIRt"},"source":["## Load sentiment data"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"jpHX8pJLxIRt","executionInfo":{"status":"ok","timestamp":1667173643467,"user_tz":240,"elapsed":1121,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["sentiments_df =  spark.read.parquet('sentiments.parquet')"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667173643468,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"2LKPx69JxIRu","outputId":"0a6a609b-1c61-435e-8778-6bca7a1e1521"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- word: string (nullable = true)\n"," |-- sentiment: long (nullable = true)\n","\n"]}],"source":["sentiments_df.printSchema()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1667173644324,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"IP8WVJhAxIRu","outputId":"add2bbef-357c-47fa-89d2-cb94c2e20884","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------+\n","|         word|sentiment|\n","+-------------+---------+\n","|   gratefully|        1|\n","|gratification|        1|\n","|    gratified|        1|\n","|    gratifies|        1|\n","|      gratify|        1|\n","+-------------+---------+\n","only showing top 5 rows\n","\n"]}],"source":["sentiments_df.show(5)"]},{"cell_type":"markdown","metadata":{"id":"xBUC0BGVxIRv"},"source":["The schema is very simple: for each word, we have whether it is positive (+1) or negative (-1)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1667173644821,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"WYeRN-YWxIRv","outputId":"3608d571-9d97-4ce9-b310-37584385cf9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------+\n","|         word|sentiment|\n","+-------------+---------+\n","|   gratefully|        1|\n","|gratification|        1|\n","|    gratified|        1|\n","|    gratifies|        1|\n","|      gratify|        1|\n","+-------------+---------+\n","only showing top 5 rows\n","\n"]}],"source":["# a sample of positive words\n","sentiments_df.where(fn.col('sentiment') == 1).show(5)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1667173645017,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"K8s2IaEZxIRw","outputId":"e06f6773-b794-48df-e3c3-aabaa6de542f"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------+\n","|      word|sentiment|\n","+----------+---------+\n","|   2-faced|       -1|\n","|   2-faces|       -1|\n","|  abnormal|       -1|\n","|   abolish|       -1|\n","|abominable|       -1|\n","+----------+---------+\n","only showing top 5 rows\n","\n"]}],"source":["# a sample of negative words\n","sentiments_df.where(fn.col('sentiment') == -1).show(5)"]},{"cell_type":"markdown","metadata":{"id":"scWKDhMjxIRw"},"source":["Lets see how many of each category we have"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1074,"status":"ok","timestamp":1667173646089,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"JZTY1PquxIRw","outputId":"fc61b2d8-f6a2-4819-a999-4bef0f15a5d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------+\n","|sentiment|count(1)|\n","+---------+--------+\n","|        1|    2006|\n","|       -1|    4783|\n","+---------+--------+\n","\n"]}],"source":["sentiments_df.groupBy('sentiment').agg(fn.count('*')).show() # the '*' means count all rows even if the row has a null value"]},{"cell_type":"markdown","metadata":{"id":"t3kaDpSZxIRx"},"source":["We have almost two times the number of negative words!"]},{"cell_type":"markdown","metadata":{"id":"MpyzpW2zxIRx"},"source":["# A simple approach to sentiment analysis"]},{"cell_type":"markdown","metadata":{"id":"Lvey7giMxIRx"},"source":["One simple approach for sentiment analysis is to simply count the number of positive and negative words in a text and then compute the average sentiment. Assuming that positive words are +1 and negative words are -1, we can classify a text as positive if the average sentiment is greater than zero and negative otherwise"]},{"cell_type":"markdown","metadata":{"id":"c0nKeEzTxIRy"},"source":["To test our approach, we will use a sample of [IMDB](http://www.imdb.com/) reviews that were tagged as positive and negative.\n","\n","Let's load them:"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":579,"status":"ok","timestamp":1667173646666,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"18QIT38gxIRy","outputId":"c63dc337-a25c-4230-915e-bda7453cd72f"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------------------+-----+\n","|       id|              review|score|\n","+---------+--------------------+-----+\n","|pos_10006|In this \"critical...|  1.0|\n","|pos_10013|Like one of the p...|  1.0|\n","|pos_10022|Aro Tolbukhin bur...|  1.0|\n","|pos_10033|The movie Titanic...|  1.0|\n","| pos_1003|Another Aussie ma...|  1.0|\n","| pos_1004|After a brief pro...|  1.0|\n","|pos_10053|I must admit, whe...|  1.0|\n","|pos_10062|Wow. What a wonde...|  1.0|\n","|pos_10074|quote by Nicolas ...|  1.0|\n","|pos_10083|The fact that thi...|  1.0|\n","+---------+--------------------+-----+\n","only showing top 10 rows\n","\n"]}],"source":["imdb_reviews_df = spark.read.parquet('imdb_reviews_preprocessed.parquet')\n","imdb_reviews_df.show(10)"]},{"cell_type":"markdown","metadata":{"id":"FVkQuzZCxIRy"},"source":["Print the unique scores in the imdb_reviews_df.  A positive review has a score of 1, and a negative review has a score of 0."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2894,"status":"ok","timestamp":1667173649558,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"WCD3EOnZxIRz","outputId":"70fbf8dc-7e14-460d-8b8f-e4ad4cff33a8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0.])"]},"metadata":{},"execution_count":24}],"source":["imdb_reviews_df.toPandas()['score'].unique()"]},{"cell_type":"markdown","metadata":{"id":"KvKxnArWxIRz"},"source":["Let's take a look at a positive review"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1667173649934,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"KvHk2-BGxIR0","outputId":"d61cedbb-36fc-49ef-c892-662d55b48de8","scrolled":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Row(id='pos_10006', review='In this \"critically acclaimed psychological thriller based on true events, Gabriel (Robin Williams), a celebrated writer and late-night talk show host, becomes captivated by the harrowing story of a young listener and his adoptive mother (Toni Collette). When troubling questions arise about this boy\\'s (story), however, Gabriel finds himself drawn into a widening mystery that hides a deadly secret\\x85\" according to film\\'s official synopsis.<br /><br />You really should STOP reading these comments, and watch the film NOW...<br /><br />The \"How did he lose his leg?\" ending, with Ms. Collette planning her new life, should be chopped off, and sent to \"deleted scenes\" land. It\\'s overkill. The true nature of her physical and mental ailments should be obvious, by the time Mr. Williams returns to New York. Possibly, her blindness could be in question - but a revelation could have be made certain in either the \"highway\" or \"video tape\" scenes. The film would benefit from a re-editing - how about a \"director\\'s cut\"? <br /><br />Williams and Bobby Cannavale (as Jess) don\\'t seem, initially, believable as a couple. A scene or two establishing their relationship might have helped set the stage. Otherwise, the cast is exemplary. Williams offers an exceptionally strong characterization, and not a \"gay impersonation\". Sandra Oh (as Anna), Joe Morton (as Ashe), and Rory Culkin (Pete Logand) are all perfect.<br /><br />Best of all, Collette\\'s \"Donna\" belongs in the creepy hall of fame. Ms. Oh is correct in saying Collette might be, \"you know, like that guy from \\'Psycho\\'.\" There have been several years when organizations giving acting awards seemed to reach for women, due to a slighter dispersion of roles; certainly, they could have noticed Collette with some award consideration. She is that good. And, director Patrick Stettner definitely evokes Hitchcock - he even makes getting a sandwich from a vending machine suspenseful.<br /><br />Finally, writers Stettner, Armistead Maupin, and Terry Anderson deserve gratitude from flight attendants everywhere.<br /><br />******* The Night Listener (1/21/06) Patrick Stettner ~ Robin Williams, Toni Collette, Sandra Oh, Rory Culkin', score=1.0)"]},"metadata":{},"execution_count":25}],"source":["imdb_reviews_df.where(fn.col('score') == 1).first()"]},{"cell_type":"markdown","metadata":{"id":"wVxArHo_xIR0"},"source":["And a negative one"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1667173650322,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"Y15-CDmZxIR1","outputId":"f5b20927-a4c1-476e-ac62-820cf55b7d73"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Row(id='neg_10006', review=\"I don't know who to blame, the timid writers or the clueless director. It seemed to be one of those movies where so much was paid to the stars (Angie, Charlie, Denise, Rosanna and Jon) that there wasn't enough left to really make a movie. This could have been very entertaining, but there was a veil of timidity, even cowardice, that hung over each scene. Since it got an R rating anyway why was the ubiquitous bubble bath scene shot with a 70-year-old woman and not Angie Harmon? Why does Sheen sleepwalk through potentially hot relationships WITH TWO OF THE MOST BEAUTIFUL AND SEXY ACTRESSES in the world? If they were only looking for laughs why not cast Whoopi Goldberg and Judy Tenuta instead? This was so predictable I was surprised to find that the director wasn't a five year old. What a waste, not just for the viewers but for the actors as well.\", score=0.0)"]},"metadata":{},"execution_count":26}],"source":["imdb_reviews_df.where(fn.col('score') == 0).first()"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"PaG-Z-3cxIR1"},"source":["The first problem that we encounter is that the reviews are in plain text. We need to split the words and then match them to `sentiment_df`.  To do this, we will use a transformation that takes raw text and outputs a list of words"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"ahQhg1kvxIR1","executionInfo":{"status":"ok","timestamp":1667173650322,"user_tz":240,"elapsed":3,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.feature import RegexTokenizer"]},{"cell_type":"markdown","metadata":{"id":"rn2yjhjzxIR1"},"source":["`RegexTokenizer` extracts a sequence of matches from the input text. Regular expressions are a powerful tool to extract strings with certain characteristics.  The pattern `\\p{L}+` means that it will extract letters without accents (e.g., it will extract \"Acuna\" from \"Acuña\") (see the following [stack overflow link](https://stackoverflow.com/questions/5969440/what-is-the-l-unicode-category) for more information). `setGaps=False` means that the regular expression applys to tokens instead of defining gaps between tokens. setInputCol defines the dataframe input column (in our case the `review` column).  setOutputCol defines the new column that will be added to the dataframe (e.g., `words`)."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"cPnOmpsxxIR2","executionInfo":{"status":"ok","timestamp":1667173650323,"user_tz":240,"elapsed":4,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["tokenizer = RegexTokenizer().setGaps(False)\\\n","  .setPattern(\"\\\\p{L}+\")\\\n","  .setInputCol(\"review\")\\\n","  .setOutputCol(\"words\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1667173650523,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"XA8_R13txIR2","outputId":"83edef6a-4e14-4d9f-de94-9a7c10c43945"},"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame[id: string, review: string, score: double, words: array<string>]\n"]}],"source":["review_words_df = tokenizer.transform(imdb_reviews_df)\n","print(review_words_df)"]},{"cell_type":"markdown","metadata":{"id":"y5vU8TWvxIR2"},"source":["Applying the transformation doesn't actually do anything until you apply an action. But as you can see, a new column `words` of type `array` of `string` was added by the transformation. We can see how it looks:"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535,"status":"ok","timestamp":1667173651055,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"pH4YKOw6xIR2","outputId":"656a94b9-c4b9-4f66-9721-61b1496c8626"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------------------+-----+--------------------+\n","|       id|              review|score|               words|\n","+---------+--------------------+-----+--------------------+\n","|pos_10006|In this \"critical...|  1.0|[in, this, critic...|\n","|pos_10013|Like one of the p...|  1.0|[like, one, of, t...|\n","|pos_10022|Aro Tolbukhin bur...|  1.0|[aro, tolbukhin, ...|\n","|pos_10033|The movie Titanic...|  1.0|[the, movie, tita...|\n","| pos_1003|Another Aussie ma...|  1.0|[another, aussie,...|\n","+---------+--------------------+-----+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["review_words_df.show(5)"]},{"cell_type":"markdown","metadata":{"id":"iV9gkILoxIR3"},"source":["Now, we want to match every word from `sentiment_df` in the array `words` shown before. One way of doing this is to _explode_ the column `words` to create a row for each element in that list. Then, we would join that result with the dataframe `sentiment` to continue further."]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1667173651451,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"2w16lRWcxIR3","outputId":"4ec5d898-4602-44a5-a8e9-c05e02317dce"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+-------------+\n","|       id|        word1|\n","+---------+-------------+\n","|pos_10006|           in|\n","|pos_10006|         this|\n","|pos_10006|   critically|\n","|pos_10006|    acclaimed|\n","|pos_10006|psychological|\n","+---------+-------------+\n","only showing top 5 rows\n","\n"]}],"source":["review_words_df.select('id', fn.explode('words').alias('word1')).show(5)"]},{"cell_type":"markdown","metadata":{"id":"oLAEmdnFxIR3"},"source":["Now if we join that with sentiment, we can see if there are positive and negative words in each review:"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1175,"status":"ok","timestamp":1667173652625,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"tnFmumsZxIR3","outputId":"330f5108-2890-4465-d4fd-2815d3e82bf3","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------+---------+\n","|      word|       id|sentiment|\n","+----------+---------+---------+\n","| acclaimed|pos_10006|        1|\n","|celebrated|pos_10006|        1|\n","| troubling|pos_10006|       -1|\n","|   mystery|pos_10006|       -1|\n","|    deadly|pos_10006|       -1|\n","+----------+---------+---------+\n","only showing top 5 rows\n","\n"]}],"source":["review_word_sentiment_df = review_words_df.\\\n","    select('id', fn.explode('words').alias('word')).\\\n","    join(sentiments_df, 'word')\n","review_word_sentiment_df.show(5)"]},{"cell_type":"markdown","metadata":{"id":"ctVlYacDxIR3"},"source":["Check the unique sentiment column values.  Sentiments should be +1 and -1 for positive and negative word sentiments respectively."]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10068,"status":"ok","timestamp":1667173662691,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"EXEaEQ-6xIR3","outputId":"b9a2ab7a-4a5a-48e1-9a5f-84d7c8fe2d85"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+------+\n","|sentiment| count|\n","+---------+------+\n","|        1|257274|\n","|       -1|241972|\n","+---------+------+\n","\n"]}],"source":["review_word_sentiment_df.groupBy(\"sentiment\").count().show()"]},{"cell_type":"markdown","metadata":{"id":"Oaza3CLhxIR4"},"source":["Now we can simply average the sentiment per review id and, say, pick positive when the average is above 0, and negative otherwise."]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11168,"status":"ok","timestamp":1667173673845,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"qVsvvbVJxIR4","outputId":"36efa98e-2ef4-48ba-e988-c1ffe99c78aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------------------+---------+\n","|       id|       avg_sentiment|predicted|\n","+---------+--------------------+---------+\n","|pos_10149| 0.42857142857142855|      1.0|\n","|pos_10377|  0.5384615384615384|      1.0|\n","| pos_1299| 0.09090909090909091|      1.0|\n","| pos_2228|-0.14285714285714285|      0.0|\n","| pos_5052|  0.7777777777777778|      1.0|\n","+---------+--------------------+---------+\n","only showing top 5 rows\n","\n"]}],"source":["simple_sentiment_prediction_df = review_word_sentiment_df.\\\n","    groupBy('id').\\\n","    agg(fn.avg('sentiment').alias('avg_sentiment')).\\\n","    withColumn('predicted', fn.when(fn.col('avg_sentiment') > 0, 1.0).otherwise(0.))\n","simple_sentiment_prediction_df.show(5)"]},{"cell_type":"markdown","metadata":{"id":"YzFCoCvhxIR4"},"source":["Now, lets compute the accuracy of our prediction"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14191,"status":"ok","timestamp":1667173688023,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"qWnewHtExIR4","outputId":"e9a51b0c-b20f-4387-fefb-0d37eb740b41"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------+\n","|     avg(correct)|\n","+-----------------+\n","|0.732231471106131|\n","+-----------------+\n","\n"]}],"source":["imdb_reviews_df.\\\n","    join(simple_sentiment_prediction_df, 'id').\\\n","    select(fn.expr('float(score == predicted)').alias('correct')).\\\n","    select(fn.avg('correct')).\\\n","    show()"]},{"cell_type":"markdown","metadata":{"id":"yvcFFT03xIR5"},"source":["Not bad with such a simple approach! But can we do better than this?"]},{"cell_type":"markdown","metadata":{"id":"0Wq3Zg2bxIR5"},"source":["## A data-driven sentiment prediction"]},{"cell_type":"markdown","metadata":{"id":"z9S4w-O5xIR5"},"source":["There are couple of problems with the previous approach:\n","1. Positive and negative words had the same weight (e.g., good == amazing)\n","1. While our dataset is artificially balanced (12500 positive and 12500 negative), there are usually more positive than negative reviews, and therefore we should bias our predictions towards positive ones."]},{"cell_type":"markdown","metadata":{"id":"hYowU1kXxIR5"},"source":["We could use __data__ to estimate the sentiment that each word is contributing to the final sentiment of a review. Given that we are trying to predict negative and positve reviews, then we can use logistic regression for such binary prediction."]},{"cell_type":"markdown","metadata":{"id":"j4hATMLqxIR5"},"source":["### From text to numerical features"]},{"cell_type":"markdown","metadata":{"id":"Xn1W2qs7xIR6"},"source":["One typical approach is to count how many times a word appears in the text and then perform a reweighting so that words that are very common are \"counted\" less."]},{"cell_type":"markdown","metadata":{"id":"zaho53m8xIR6"},"source":["In Spark, we can achieve this by using several transformers:\n","\n","__Raw text => Tokens => Remove stop words => Term Frequency => Reweighting by Inverse Document frequency__"]},{"cell_type":"markdown","metadata":{"id":"8K7RXPwsxIR6"},"source":["To perform this sequence we will create a __`Pipeline`__ to consistently represent the steps from raw text to TF-IDF."]},{"cell_type":"markdown","metadata":{"id":"IA9Cgv3_xIR6"},"source":["First, we need to create a sequence to take from raw text to term frequency. This is necessary because we don't know the number of tokens in the text and therefore we need to _estimate_ such quantity from the data."]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1667173897428,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"ymUHPVMtxIR7","outputId":"34a643f5-9357-4989-a042-70d508b31d3f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a',\n"," 'about',\n"," 'above',\n"," 'across',\n"," 'after',\n"," 'afterwards',\n"," 'again',\n"," 'against',\n"," 'all',\n"," 'almost']"]},"metadata":{},"execution_count":37}],"source":["# we obtain the stop words from a website\n","import requests\n","stop_words = requests.get('https://raw.githubusercontent.com/wewilli1/ist718_data/master/stop_words.txt').text.split()\n","stop_words[0:10]"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"xvLCgP_FxIR7","executionInfo":{"status":"ok","timestamp":1667173897768,"user_tz":240,"elapsed":195,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.feature import StopWordsRemover\n","sw_filter = StopWordsRemover()\\\n","  .setStopWords(stop_words)\\\n","  .setCaseSensitive(False)\\\n","  .setInputCol(\"words\")\\\n","  .setOutputCol(\"filtered\")"]},{"cell_type":"markdown","metadata":{"id":"961HyB8yxIR7"},"source":["Finally, for this initial `Pipeline`, we define a [CountVectorizer](https://spark.apache.org/docs/latest/ml-features.html#countvectorizer) estimator.  Note that the vocabSize param is used to limit the size of the vocabulary in cases where you have a very large vocabulary and perhaps you want to limit the size of the vocabulary to decrease model training time, or increase the vocabulary size because the default size is less than the vocabulary size in your data set.  You shouldn't change the vocabulary size unless you do an analysis and change the size for a reason."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"plaObL4fxIR8","executionInfo":{"status":"ok","timestamp":1667173897768,"user_tz":240,"elapsed":2,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.feature import CountVectorizer\n","\n","# we will remove words that appear in 5 docs or less\n","cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n","  .setInputCol(\"filtered\")\\\n","  .setOutputCol(\"tf\")"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"vzFS4tVgxIR8","scrolled":false,"executionInfo":{"status":"ok","timestamp":1667173907836,"user_tz":240,"elapsed":10070,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["# we now create a pipelined transformer\n","cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(imdb_reviews_df)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":937,"status":"ok","timestamp":1667173908759,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"5hlntQ9rxIR8","outputId":"2b198f3f-4096-4878-e9c5-12c44eb5c71d"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------------------+-----+--------------------+--------------------+--------------------+\n","|       id|              review|score|               words|            filtered|                  tf|\n","+---------+--------------------+-----+--------------------+--------------------+--------------------+\n","|pos_10006|In this \"critical...|  1.0|[in, this, critic...|[critically, accl...|(26677,[0,1,3,4,5...|\n","|pos_10013|Like one of the p...|  1.0|[like, one, of, t...|[like, previous, ...|(26677,[1,2,3,4,5...|\n","|pos_10022|Aro Tolbukhin bur...|  1.0|[aro, tolbukhin, ...|[aro, tolbukhin, ...|(26677,[0,1,2,12,...|\n","|pos_10033|The movie Titanic...|  1.0|[the, movie, tita...|[movie, titanic, ...|(26677,[0,1,2,3,4...|\n","| pos_1003|Another Aussie ma...|  1.0|[another, aussie,...|[aussie, masterpi...|(26677,[4,5,9,24,...|\n","+---------+--------------------+-----+--------------------+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# now we can make the transformation between the raw text and the counts\n","cv_pipeline.transform(imdb_reviews_df).show(5)"]},{"cell_type":"markdown","metadata":{"id":"j7gBFP3vxIR9"},"source":["The term frequency vector is represented with a sparse vector. We have 26,677 terms."]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1667173908963,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"RWiqS9hFxIR9","outputId":"85696b63-046e-461c-830d-b3582cdc4bbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["26677"]},"metadata":{},"execution_count":42}],"source":["len(cv_pipeline.stages[-1].vocabulary)"]},{"cell_type":"markdown","metadata":{"id":"8p4bZ2ZxxIR9"},"source":["Finally, we build another pipeline that takes the output of the previous pipeline and _lowers_ the terms of documents that are very common."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"yblADhIVxIR-","executionInfo":{"status":"ok","timestamp":1667173908963,"user_tz":240,"elapsed":2,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.feature import IDF\n","idf = IDF().\\\n","    setInputCol('tf').\\\n","    setOutputCol('tfidf')"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"6wpC9WSuxIR-","executionInfo":{"status":"ok","timestamp":1667173917588,"user_tz":240,"elapsed":8627,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(imdb_reviews_df)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":774,"status":"ok","timestamp":1667173918348,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"GMxYn98SxIR-","outputId":"8af4f699-5d84-4350-9c23-58ea57af756e"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|tfidf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|(26677,[0,1,3,4,5,7,8,9,10,14,21,24,26,29,30,31,37,38,46,48,51,54,59,64,88,116,125,129,150,189,200,202,222,227,230,232,239,243,256,260,263,269,328,347,356,364,368,377,392,432,452,454,472,486,514,517,521,541,567,570,582,627,630,631,634,647,650,651,673,704,747,750,952,1058,1083,1159,1255,1302,1317,1323,1325,1400,1406,1465,1473,1474,1530,1572,1664,1701,1799,1817,1818,1830,1842,1917,1954,2008,2010,2011,2023,2115,2194,2278,2452,2457,2879,2955,3023,3118,3288,3290,3524,3604,3609,3637,3797,3928,4065,4338,4521,4789,5064,5156,5208,5601,5758,5914,6093,6206,6254,6341,6379,7181,7193,7516,7946,9907,9932,10162,10394,10480,10786,12079,12553,13581,14733,14793,15840,16275,17873,20551,22966,23784,24430,26224],[6.399789021643247,1.5355439272599614,1.751599547551507,0.5028974533168351,0.7612090942068761,0.9527872680847915,1.051577880482202,2.375491662124171,1.1869590489601298,1.3491156498373038,1.5198200397035864,1.6887375926197539,1.53920585864879,1.6292725389623013,1.6586681558248935,1.6538478593700623,1.8765733504775144,3.705648340531702,1.9247367518561371,3.905063519241778,4.097206442469843,1.9536597913253875,2.044577824871977,2.2186516584178886,2.4178115020031847,2.4609176711886604,2.553139840304409,5.076694851430274,5.339278027855957,2.950416571033215,2.899008604321704,2.8228278777726548,2.8577509748566374,2.9121666888992155,2.8732007203658316,3.0349289879552064,2.895384098722744,3.1456653623286295,2.951946793213983,8.994525472110968,3.2555798084398138,2.949652337140459,3.125425480980883,3.210947654419045,3.2059995988016756,3.2576566523846524,3.216917821405549,3.2350452059981056,3.3365738675364547,3.437071833871393,3.3980424899656576,3.360479388390009,3.4802805882026293,3.522727278449887,3.5755907680069545,3.5336265689079225,3.4470719172059763,3.6969516250112218,3.5784520002879865,3.5755907680069545,3.572737699024548,3.7987343193211642,3.6223829295137135,3.734753989657757,3.62538143250997,4.135206555942377,3.7083061671141477,3.6652029266966415,3.734753989657757,3.8462752640901643,3.916071026025706,4.205092683406543,4.1105139433520055,4.115403928646197,4.205092683406543,4.224037769648993,4.367769329173078,9.116653198578526,4.3306133522849874,4.383667915240877,23.37816324742329,4.4096434016441375,4.577595018155139,4.495459321228993,4.467188887290738,4.499049989359722,4.467188887290738,4.506270237333209,4.546941277064137,4.662839298024749,5.206690177222234,4.728508401532606,9.93523160767166,4.692949099496119,4.798794934260778,4.779563572332891,4.7421760402612705,4.756033074922696,10.128152140046785,5.096233181657924,4.89022914022041,5.129458829286244,4.933714252160149,4.900924429337158,4.996772388127286,5.192197169919667,5.266858698688687,5.185028680441055,5.5833763207803555,5.251473779849207,5.3391793602683135,5.330880557453618,5.863991226009044,5.707830495253761,5.63803473331822,5.472710752892835,5.5115505862091,5.501698289766088,12.167239670431618,12.510940184284935,5.672323806796851,6.10131941231521,5.795937762764028,6.276523501340301,5.921978483659393,5.967788019690687,6.06622809250394,12.64001722656008,6.083619835215809,6.06622809250394,39.258912987565495,6.10131941231521,6.137687056486085,6.298029706561264,6.298029706561264,6.32000861328004,13.66166847409206,6.725473721388203,6.794466592875155,13.98235377424242,6.83083423704603,14.071257299384087,7.035628649692043,6.99117688712121,7.082148665326936,7.182232123883919,7.293457758994143,7.354082380810578,7.4876137734351005,7.561721745588822,7.824086010056313,8.047229561370523,8.047229561370523,8.334911633822305,8.180760953995046,8.334911633822305])|\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 1 row\n","\n"]}],"source":["idf_pipeline.transform(imdb_reviews_df).select('tfidf').show(1, False)"]},{"cell_type":"markdown","metadata":{"id":"z4t5gwkaxIR-"},"source":["Therefore, the `idf_pipeline` takes the raw text from the datafarme `imdb_reviews_df` and creates a feature vector called `tfidf`!"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1667173918963,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"AeHk4y_6xIR_","outputId":"f7e9db69-9faf-48c9-a57d-e5adcf78ceef"},"outputs":[{"output_type":"stream","name":"stdout","text":["tfidf_df shape:  25000 7\n"]}],"source":["tfidf_df = idf_pipeline.transform(imdb_reviews_df)\n","print(\"tfidf_df shape: \", tfidf_df.count(), len(tfidf_df.columns))"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1667173919350,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"bMdRX_LcxIR_","outputId":"a45e733d-b0c4-453d-c7ac-75e78188bf34"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n","|       id|              review|score|               words|            filtered|                  tf|               tfidf|\n","+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n","|pos_10006|In this \"critical...|  1.0|[in, this, critic...|[critically, accl...|(26677,[0,1,3,4,5...|(26677,[0,1,3,4,5...|\n","|pos_10013|Like one of the p...|  1.0|[like, one, of, t...|[like, previous, ...|(26677,[1,2,3,4,5...|(26677,[1,2,3,4,5...|\n","|pos_10022|Aro Tolbukhin bur...|  1.0|[aro, tolbukhin, ...|[aro, tolbukhin, ...|(26677,[0,1,2,12,...|(26677,[0,1,2,12,...|\n","|pos_10033|The movie Titanic...|  1.0|[the, movie, tita...|[movie, titanic, ...|(26677,[0,1,2,3,4...|(26677,[0,1,2,3,4...|\n","| pos_1003|Another Aussie ma...|  1.0|[another, aussie,...|[aussie, masterpi...|(26677,[4,5,9,24,...|(26677,[4,5,9,24,...|\n","+---------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["tfidf_df.show(5)"]},{"cell_type":"markdown","metadata":{"id":"reAFgx4-xIR_"},"source":["The cell below prints out the 'tf' and 'tfidf' columns for the first 10 rows of the tfidf_df.  Note that the tfidf column is transformed to account for the frequency with which the word appears in the corpus.  Words that appear more often are penalized more than words that do not appear as frequently in the corpus."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1667173919720,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"2A-BGl3UxIR_","outputId":"dd218d70-6248-42c5-e311-e411dc7bf704"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  tf  \\\n","0  (12.0, 5.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0,...   \n","1  (0.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, ...   \n","2  (6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n","3  (6.0, 1.0, 3.0, 7.0, 3.0, 2.0, 1.0, 0.0, 2.0, ...   \n","4  (0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n","5  (14.0, 7.0, 1.0, 6.0, 2.0, 0.0, 2.0, 3.0, 1.0,...   \n","6  (6.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, ...   \n","7  (6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n","8  (4.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n","9  (6.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...   \n","\n","                                               tfidf  \n","0  (6.399789021643247, 1.5355439272599614, 0.0, 1...  \n","1  (0.0, 0.6142175709039845, 1.9611159574304948, ...  \n","2  (3.1998945108216237, 0.6142175709039845, 0.490...  \n","3  (3.1998945108216237, 0.30710878545199227, 1.47...  \n","4  (0.0, 0.0, 0.0, 0.0, 0.5028974533168351, 0.761...  \n","5  (7.466420525250455, 2.149761498163946, 0.49027...  \n","6  (3.1998945108216237, 0.6142175709039845, 1.470...  \n","7  (3.1998945108216237, 0.0, 0.0, 1.1677330317010...  \n","8  (2.1332630072144156, 0.0, 0.0, 2.3354660634020...  \n","9  (3.1998945108216237, 0.30710878545199227, 0.0,...  "],"text/html":["\n","  <div id=\"df-66779822-08bf-469a-b6e3-c07e4d20e527\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tf</th>\n","      <th>tfidf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(12.0, 5.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0,...</td>\n","      <td>(6.399789021643247, 1.5355439272599614, 0.0, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(0.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, ...</td>\n","      <td>(0.0, 0.6142175709039845, 1.9611159574304948, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>(3.1998945108216237, 0.6142175709039845, 0.490...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(6.0, 1.0, 3.0, 7.0, 3.0, 2.0, 1.0, 0.0, 2.0, ...</td>\n","      <td>(3.1998945108216237, 0.30710878545199227, 1.47...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>(0.0, 0.0, 0.0, 0.0, 0.5028974533168351, 0.761...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>(14.0, 7.0, 1.0, 6.0, 2.0, 0.0, 2.0, 3.0, 1.0,...</td>\n","      <td>(7.466420525250455, 2.149761498163946, 0.49027...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>(6.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n","      <td>(3.1998945108216237, 0.6142175709039845, 1.470...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>(6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>(3.1998945108216237, 0.0, 0.0, 1.1677330317010...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>(4.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>(2.1332630072144156, 0.0, 0.0, 2.3354660634020...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>(6.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n","      <td>(3.1998945108216237, 0.30710878545199227, 0.0,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66779822-08bf-469a-b6e3-c07e4d20e527')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-66779822-08bf-469a-b6e3-c07e4d20e527 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-66779822-08bf-469a-b6e3-c07e4d20e527');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":48}],"source":["tfidf_df.limit(10).toPandas().loc[:10, ['tf', 'tfidf']]"]},{"cell_type":"markdown","metadata":{"id":"d_GrLxN_xISA"},"source":["# Data science pipeline for estimating sentiments"]},{"cell_type":"markdown","metadata":{"id":"HD2GSwpzxISA"},"source":["First, let's split the data into training, validation, and testing."]},{"cell_type":"code","execution_count":49,"metadata":{"id":"M4GQx52NxISA","executionInfo":{"status":"ok","timestamp":1667173919865,"user_tz":240,"elapsed":149,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["training_df, validation_df, testing_df = imdb_reviews_df.randomSplit([0.6, 0.3, 0.1], seed=0)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":586,"status":"ok","timestamp":1667173920449,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"jiPlbBKwxISA","outputId":"0836a24e-3084-4fd3-b324-df9cdf3bf420"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id                                             review  score\n","0      neg_1  Robert DeNiro plays the most unbelievably inte...    0.0\n","1     neg_10  This film had a lot of promise, and the plot w...    0.0\n","2    neg_100  OK its not the best film I've ever seen but at...    0.0\n","3  neg_10000  Airport '77 starts as a brand new luxury 747 p...    0.0\n","4  neg_10001  This film lacked something I couldn't put my f...    0.0"],"text/html":["\n","  <div id=\"df-a2351153-6120-414c-8801-1b732b3dd673\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>review</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neg_1</td>\n","      <td>Robert DeNiro plays the most unbelievably inte...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>neg_10</td>\n","      <td>This film had a lot of promise, and the plot w...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>neg_100</td>\n","      <td>OK its not the best film I've ever seen but at...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>neg_10000</td>\n","      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>neg_10001</td>\n","      <td>This film lacked something I couldn't put my f...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2351153-6120-414c-8801-1b732b3dd673')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a2351153-6120-414c-8801-1b732b3dd673 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a2351153-6120-414c-8801-1b732b3dd673');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":50}],"source":["training_df.limit(5).toPandas()"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1564,"status":"ok","timestamp":1667173922011,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"gZf_lLyFxISA","outputId":"c46545c0-57cf-48f5-9f91-71add74cfd1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[14962, 7531, 2507]"]},"metadata":{},"execution_count":51}],"source":["[training_df.count(), validation_df.count(), testing_df.count()]"]},{"cell_type":"markdown","metadata":{"id":"A_47vqlOxISB"},"source":["One immediately apparent problem is that the number of features in the dataset is far larger than the number of training examples. This can lead to serious overfitting.\n","\n","Let's look at this more closely. Let's apply a simple prediction model known as logistic regression.\n","\n","[Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) will take the `tfidf` features and predict whether the review is positive (`score == 1`) or negative (`score == 0`)."]},{"cell_type":"code","execution_count":52,"metadata":{"id":"Fdka3EbwxISB","executionInfo":{"status":"ok","timestamp":1667173922011,"user_tz":240,"elapsed":3,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.classification import LogisticRegression"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"9-regoT4xISB","executionInfo":{"status":"ok","timestamp":1667173922181,"user_tz":240,"elapsed":172,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["lr = LogisticRegression().\\\n","    setLabelCol('score').\\\n","    setFeaturesCol('tfidf').\\\n","    setRegParam(0.0).\\\n","    setMaxIter(100).\\\n","    setElasticNetParam(0.)"]},{"cell_type":"markdown","metadata":{"id":"gHqgsAZAxISB"},"source":["Lets create a pipeline transformation by chaining the `idf_pipeline` with the logistic regression step (`lr`)"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"tCjjqRtsxISB","executionInfo":{"status":"ok","timestamp":1667173939933,"user_tz":240,"elapsed":17753,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["lr_pipeline = Pipeline(stages=[idf_pipeline, lr]).fit(training_df)"]},{"cell_type":"markdown","metadata":{"id":"SBB_IB84xISB"},"source":["The next cell defines a class capable of calculating ROC and PR curves.  The following cell creates a ROC curve using transformed data from the pipeline above."]},{"cell_type":"code","execution_count":55,"metadata":{"id":"ttXENJtgxISC","executionInfo":{"status":"ok","timestamp":1667173939933,"user_tz":240,"elapsed":14,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["# see https://stackoverflow.com/questions/52847408/pyspark-extract-roc-curve\n","from pyspark.mllib.evaluation import BinaryClassificationMetrics\n","\n","# Scala version implements .roc() and .pr()\n","# Python: https://spark.apache.org/docs/latest/api/python/_modules/pyspark/mllib/common.html\n","# Scala: https://spark.apache.org/docs/latest/api/java/org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html\n","class CurveMetrics(BinaryClassificationMetrics):\n","    def __init__(self, *args):\n","        super(CurveMetrics, self).__init__(*args)\n","\n","    def _to_list(self, rdd):\n","        points = []\n","        # Note this collect could be inefficient for large datasets \n","        # considering there may be one probability per datapoint (at most)\n","        # The Scala version takes a numBins parameter, \n","        # but it doesn't seem possible to pass this from Python to Java\n","        for row in rdd.collect():\n","            # Results are returned as type scala.Tuple2, \n","            # which doesn't appear to have a py4j mapping\n","            points += [(float(row._1()), float(row._2()))]\n","        return points\n","\n","    def get_curve(self, method):\n","        rdd = getattr(self._java_model, method)().toJavaRDD()\n","        return self._to_list(rdd)"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"elapsed":7352,"status":"ok","timestamp":1667173947271,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"2sPP9J1GxISC","outputId":"271e3ae2-2402-4fcb-9643-087357ed6aed","scrolled":false},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:159: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  FutureWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f8f75c0c110>]"]},"metadata":{},"execution_count":56},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","\n","# Create a Pipeline estimator and fit on train DF, predict on test DF\n","predictions = lr_pipeline.transform(validation_df)\n","\n","# Returns as a list (false positive rate, true positive rate)\n","preds = predictions.select('score','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['score'])))\n","points = CurveMetrics(preds).get_curve('roc')\n","\n","plt.figure()\n","x_val = [x[0] for x in points]\n","y_val = [x[1] for x in points]\n","plt.title('IMDB Sentiment Analysis ROC Curve')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.plot(x_val, y_val)"]},{"cell_type":"markdown","metadata":{"id":"Cdx9KsOqxISC"},"source":["Lets estimate the accuracy:"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3186,"status":"ok","timestamp":1667173950455,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"AyCDe7jwxISC","outputId":"bdc86896-5a16-4505-d996-c909b29305e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------+\n","|      avg(correct)|\n","+------------------+\n","|0.8358783694064533|\n","+------------------+\n","\n"]}],"source":["lr_pipeline.transform(validation_df).\\\n","    select(fn.expr('float(prediction = score)').alias('correct')).\\\n","    select(fn.avg('correct')).show()"]},{"cell_type":"markdown","metadata":{"id":"qKkglLvMxISC"},"source":["The performance is much better than before.\n","\n","The problem however is that we are overfitting because we have many features compared to the training examples:"]},{"cell_type":"markdown","metadata":{"id":"VTQmUsd_xISD"},"source":["For example, if we look at the weights of the features, there is a lot of noise:"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"elapsed":770,"status":"ok","timestamp":1667173951213,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"oyTClyPVxISD","outputId":"ed7d6d6f-95a3-4d4c-ddb6-5fb79c656ff0"},"outputs":[{"output_type":"stream","name":"stdout","text":["num weights: 26677\n","num rows: 7531\n"]},{"output_type":"execute_result","data":{"text/plain":["    word    weight\n","0     br -0.100481\n","1      s  0.160625\n","2  movie -0.328053\n","3   film  0.185518\n","4      t -0.691525"],"text/html":["\n","  <div id=\"df-b672dff6-abb1-4833-a660-742c74dc543c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>br</td>\n","      <td>-0.100481</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>s</td>\n","      <td>0.160625</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>movie</td>\n","      <td>-0.328053</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>film</td>\n","      <td>0.185518</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>t</td>\n","      <td>-0.691525</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b672dff6-abb1-4833-a660-742c74dc543c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b672dff6-abb1-4833-a660-742c74dc543c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b672dff6-abb1-4833-a660-742c74dc543c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":58}],"source":["import pandas as pd\n","vocabulary = idf_pipeline.stages[0].stages[-1].vocabulary\n","weights = lr_pipeline.stages[-1].coefficients.toArray()\n","print(\"num weights:\", len(weights))\n","print(\"num rows:\", validation_df.count())\n","\n","coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})\n","coeffs_df.head()"]},{"cell_type":"markdown","metadata":{"id":"cVgEeVn-xISD"},"source":["The most negative words are:"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667173951214,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"zCafkdj_xISD","outputId":"502974f6-a418-4405-db30-31c1c103ca55"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            word    weight\n","21358  grossness -5.535871\n","24601  zoolander -5.522390\n","25715    residue -5.299288\n","26178      dunes -5.196362\n","23878  publicize -5.089870"],"text/html":["\n","  <div id=\"df-6eca4b12-0522-48a1-bd1b-0e85bc7974d5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21358</th>\n","      <td>grossness</td>\n","      <td>-5.535871</td>\n","    </tr>\n","    <tr>\n","      <th>24601</th>\n","      <td>zoolander</td>\n","      <td>-5.522390</td>\n","    </tr>\n","    <tr>\n","      <th>25715</th>\n","      <td>residue</td>\n","      <td>-5.299288</td>\n","    </tr>\n","    <tr>\n","      <th>26178</th>\n","      <td>dunes</td>\n","      <td>-5.196362</td>\n","    </tr>\n","    <tr>\n","      <th>23878</th>\n","      <td>publicize</td>\n","      <td>-5.089870</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6eca4b12-0522-48a1-bd1b-0e85bc7974d5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6eca4b12-0522-48a1-bd1b-0e85bc7974d5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6eca4b12-0522-48a1-bd1b-0e85bc7974d5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":59}],"source":["coeffs_df.sort_values('weight').head(5)"]},{"cell_type":"markdown","metadata":{"id":"yiumrlvjxISE"},"source":["And the most positive:"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1667173951214,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"DD2NIwouxISE","outputId":"474129a3-122d-48f3-9bd5-4f3bcde315df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               word    weight\n","25595   silhouetted  7.924966\n","20816         choco  7.319013\n","25046     eliciting  5.696226\n","21004  praiseworthy  5.584179\n","13619        shrewd  5.534538"],"text/html":["\n","  <div id=\"df-48ab3317-54cc-49a3-8cfe-bb7a88ac2598\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25595</th>\n","      <td>silhouetted</td>\n","      <td>7.924966</td>\n","    </tr>\n","    <tr>\n","      <th>20816</th>\n","      <td>choco</td>\n","      <td>7.319013</td>\n","    </tr>\n","    <tr>\n","      <th>25046</th>\n","      <td>eliciting</td>\n","      <td>5.696226</td>\n","    </tr>\n","    <tr>\n","      <th>21004</th>\n","      <td>praiseworthy</td>\n","      <td>5.584179</td>\n","    </tr>\n","    <tr>\n","      <th>13619</th>\n","      <td>shrewd</td>\n","      <td>5.534538</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48ab3317-54cc-49a3-8cfe-bb7a88ac2598')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-48ab3317-54cc-49a3-8cfe-bb7a88ac2598 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-48ab3317-54cc-49a3-8cfe-bb7a88ac2598');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":60}],"source":["coeffs_df.sort_values('weight', ascending=False).head(5)"]},{"cell_type":"markdown","metadata":{"id":"C28LeMugxISE"},"source":["But none of them make sense. What is happening? We are overfitting the data. Those words that don't make sense are capturing just noise in the reviews."]},{"cell_type":"markdown","metadata":{"id":"NzQDrj99xISF"},"source":["# Regularization"]},{"cell_type":"markdown","metadata":{"id":"2kS97ZsIxISF"},"source":["One way to prevent overfitting during training is to modify the loss function and penalize weight values that are too large.\n","\n","There are two major regularization techniques, one based on penalizing the squared value of the weight (called L2 or ridge regularization) and another based on penalizing the absolute value of the weight (called L1 or lasso regularization).\n","\n","The unregularized logistic regression loss function is:\n","\n","\\begin{equation}\n","L_\\theta(p(X),Y) = - \\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log (1-p_\\theta(X_i)) \\right)\n","\\end{equation}\n","\n","where $p_\\theta(\\cdot)$ is the sigmoid function:\n","\n","\\begin{equation}\n","p_\\theta(X) = \\frac{1}{1+\\exp(-(\\theta_0 + \\sum_{j>0} x_j \\theta_j))}\n","\\end{equation}\n","\n","If we modify the loss function $L_\\theta$ slightly\n","\n","\\begin{equation}\n","L_\\theta^{\\lambda}(p(X),Y) = -\\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log(1-p_\\theta(X_i)) \\right) + \\lambda \\sum_{j>0} \\theta_j^2\n","\\end{equation}\n","\n","we obtain what is known as L2 regularization.\n","\n","Notice how we increase the loss function by $\\lambda$ times the square of the weights. In practice, this means that __we will think twice about increasing the importance of a feature__. This loss function will prevent the algorithm for fitting certain data points, such as outliers or noise, unless the decrease in loss for the data grants it. Also, notice that the penalization doesn't apply to the bias parameter $\\theta_0$.\n","\n","You can see more clearly the effect of such cost function when $\\lambda$ goes to infinity: the features will not be used for predicting and only the bias term will matter! This prevents the algorithm from learning altogether, forcing it to underfit!\n","\n","One problem with L2 regularization is that all weights go to zero uniformly. In a sense, all features will matter but less than with the unregularized loss function. This is a really strange because we do not want all features to matter. In sentiment analysis, we want to select certain features because we want to understand that only some words have effects on the sentiment.\n","\n","A different modification of the original loss function can achieve this. This regularization is known as L1 or lasso reguarlization and penalizes the _absolute_ value of the weight\n","\n","\\begin{equation}\n","L_\\theta^{\\lambda}(p(X),Y) = -\\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log(1-p_\\theta(X_i)) \\right) + \\lambda \\sum_{j>0} \\left| \\theta_j \\right|\n","\\end{equation}\n","\n","The practical effect of L1 regularization is that the difference between a feature having no importance vs some small importance is massively bigger than with L2 regularization. __Therefore, optimizing the L1 loss function usually brings some features to have exactly zero weight.__\n","\n","One problem with L1 regularization is that it will never select more features than the number of examples. This is because it can always fit the training data perfectly when the number of features equals the number of examples. In our sentimental analysis, this is the case (there are more words than examples).\n","\n","One way of remedying this is to have a combination of both L1 and L2. This is known as __elastic net regularization__. For this type of regularization, we have to pick a parameter ($\\alpha$) deciding to consider L1 vs L2 regularization. If $\\alpha=0$, then we choose L2, and if $\\alpha=1$ we choose L1. For example, $\\alpha=0.5$ means half L1 and half L2.\n","\n","\\begin{equation}\n","L_\\theta^{\\lambda,\\alpha}(p(X),Y) = -\\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log (1-p_\\theta(X_i)) \\right) + \\lambda \\left[(1-\\alpha) \\sum_{j>0} \\theta_j^2 + \\alpha \\sum_{j>0} \\left| \\theta_j \\right| \\right]\n","\\end{equation}\n","\n","Unfortunately, elastic net regularization comes with two additional parameters, $\\lambda$ and $\\alpha$, and we must either select them a priori or use the validation set to choose the best one."]},{"cell_type":"markdown","metadata":{"id":"JfiIwwIFxISF"},"source":["## Spark allows us to fit elastic net regularization easily"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"V6yqrn-_xISG","executionInfo":{"status":"ok","timestamp":1667173951387,"user_tz":240,"elapsed":5,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["lambda_par = 0.02\n","alpha_par = 0.3\n","en_lr = LogisticRegression().\\\n","        setLabelCol('score').\\\n","        setFeaturesCol('tfidf').\\\n","        setRegParam(lambda_par).\\\n","        setMaxIter(100).\\\n","        setElasticNetParam(alpha_par)"]},{"cell_type":"markdown","metadata":{"id":"Q7vrdk23xISG"},"source":["And we define a new Pipeline with all steps combined"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"gNwXGO4mxISH","executionInfo":{"status":"ok","timestamp":1667173951388,"user_tz":240,"elapsed":5,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["en_lr_estimator = Pipeline(stages=[tokenizer, sw_filter, cv, idf, en_lr])"]},{"cell_type":"code","source":[],"metadata":{"id":"ScZKsVwr1Tpd","executionInfo":{"status":"ok","timestamp":1667173951388,"user_tz":240,"elapsed":5,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","execution_count":63,"metadata":{"id":"EiZ-a6zKxISH","executionInfo":{"status":"ok","timestamp":1667173980406,"user_tz":240,"elapsed":29023,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["en_lr_pipeline = en_lr_estimator.fit(training_df)"]},{"cell_type":"markdown","metadata":{"id":"9ErnJk2VxISH"},"source":["Let's look at the performance"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3211,"status":"ok","timestamp":1667173983601,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"548pM-3KxISH","outputId":"ed8b24b2-0a0c-4ed3-d1d5-30478f692969"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------+\n","|avg((prediction = score))|\n","+-------------------------+\n","|       0.8688089231177798|\n","+-------------------------+\n","\n"]}],"source":["en_lr_pipeline.transform(validation_df).select(fn.avg(fn.expr('float(prediction = score)'))).show()"]},{"cell_type":"markdown","metadata":{"id":"gMT47qWdxISI"},"source":["We improve performance slightly, but whats more important is that we improve the understanding of the word sentiments. Lets look at the weights:"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"7aaIUGSqxISI","executionInfo":{"status":"ok","timestamp":1667173983812,"user_tz":240,"elapsed":213,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["en_weights = en_lr_pipeline.stages[-1].coefficients.toArray()\n","en_coeffs_df = pd.DataFrame({'word': en_lr_pipeline.stages[2].vocabulary, 'weight': en_weights})"]},{"cell_type":"markdown","metadata":{"id":"DW0qFNCWxISI"},"source":["The most negative words all make sense (\"worst\" is _actually_ more negative than than \"worse\")!"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1667173983813,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"9DlvlWy3xISI","outputId":"b5b38aa6-a02e-4b56-d1e9-5188b28a3823"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                word    weight\n","105            worst -0.369175\n","262            waste -0.334129\n","190            awful -0.259523\n","12               bad -0.238963\n","606           poorly -0.185563\n","522             dull -0.185538\n","1113  disappointment -0.181959\n","184           boring -0.180374\n","179             poor -0.177841\n","243            worse -0.173746\n","351         horrible -0.172035\n","1380       redeeming -0.163210\n","1180   disappointing -0.154671\n","579            avoid -0.152661\n","1031       laughable -0.151918"],"text/html":["\n","  <div id=\"df-d36046ec-8944-4888-b0d1-5f2cd0ae7eae\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>105</th>\n","      <td>worst</td>\n","      <td>-0.369175</td>\n","    </tr>\n","    <tr>\n","      <th>262</th>\n","      <td>waste</td>\n","      <td>-0.334129</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>awful</td>\n","      <td>-0.259523</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>bad</td>\n","      <td>-0.238963</td>\n","    </tr>\n","    <tr>\n","      <th>606</th>\n","      <td>poorly</td>\n","      <td>-0.185563</td>\n","    </tr>\n","    <tr>\n","      <th>522</th>\n","      <td>dull</td>\n","      <td>-0.185538</td>\n","    </tr>\n","    <tr>\n","      <th>1113</th>\n","      <td>disappointment</td>\n","      <td>-0.181959</td>\n","    </tr>\n","    <tr>\n","      <th>184</th>\n","      <td>boring</td>\n","      <td>-0.180374</td>\n","    </tr>\n","    <tr>\n","      <th>179</th>\n","      <td>poor</td>\n","      <td>-0.177841</td>\n","    </tr>\n","    <tr>\n","      <th>243</th>\n","      <td>worse</td>\n","      <td>-0.173746</td>\n","    </tr>\n","    <tr>\n","      <th>351</th>\n","      <td>horrible</td>\n","      <td>-0.172035</td>\n","    </tr>\n","    <tr>\n","      <th>1380</th>\n","      <td>redeeming</td>\n","      <td>-0.163210</td>\n","    </tr>\n","    <tr>\n","      <th>1180</th>\n","      <td>disappointing</td>\n","      <td>-0.154671</td>\n","    </tr>\n","    <tr>\n","      <th>579</th>\n","      <td>avoid</td>\n","      <td>-0.152661</td>\n","    </tr>\n","    <tr>\n","      <th>1031</th>\n","      <td>laughable</td>\n","      <td>-0.151918</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d36046ec-8944-4888-b0d1-5f2cd0ae7eae')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d36046ec-8944-4888-b0d1-5f2cd0ae7eae button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d36046ec-8944-4888-b0d1-5f2cd0ae7eae');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":66}],"source":["en_coeffs_df.sort_values('weight').head(15)"]},{"cell_type":"markdown","metadata":{"id":"1z7K96ZOxISI"},"source":["Same thing with positive words"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1667173983814,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"jGMk2LazxISJ","outputId":"2f25a78a-ac5c-4efd-f862-c34a3349b84a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            word    weight\n","13         great  0.283820\n","161    excellent  0.240272\n","221    wonderful  0.200141\n","26          best  0.168687\n","300     favorite  0.161674\n","227      perfect  0.157916\n","286      amazing  0.142480\n","888   incredible  0.139637\n","271        loved  0.133010\n","2046  refreshing  0.129359\n","1954    captures  0.127794\n","311      enjoyed  0.125050\n","699    perfectly  0.123768\n","310        today  0.122011\n","3030    flawless  0.120522"],"text/html":["\n","  <div id=\"df-07cc4dcf-b12c-43bb-a435-18038728c335\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13</th>\n","      <td>great</td>\n","      <td>0.283820</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>excellent</td>\n","      <td>0.240272</td>\n","    </tr>\n","    <tr>\n","      <th>221</th>\n","      <td>wonderful</td>\n","      <td>0.200141</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>best</td>\n","      <td>0.168687</td>\n","    </tr>\n","    <tr>\n","      <th>300</th>\n","      <td>favorite</td>\n","      <td>0.161674</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>perfect</td>\n","      <td>0.157916</td>\n","    </tr>\n","    <tr>\n","      <th>286</th>\n","      <td>amazing</td>\n","      <td>0.142480</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>incredible</td>\n","      <td>0.139637</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>loved</td>\n","      <td>0.133010</td>\n","    </tr>\n","    <tr>\n","      <th>2046</th>\n","      <td>refreshing</td>\n","      <td>0.129359</td>\n","    </tr>\n","    <tr>\n","      <th>1954</th>\n","      <td>captures</td>\n","      <td>0.127794</td>\n","    </tr>\n","    <tr>\n","      <th>311</th>\n","      <td>enjoyed</td>\n","      <td>0.125050</td>\n","    </tr>\n","    <tr>\n","      <th>699</th>\n","      <td>perfectly</td>\n","      <td>0.123768</td>\n","    </tr>\n","    <tr>\n","      <th>310</th>\n","      <td>today</td>\n","      <td>0.122011</td>\n","    </tr>\n","    <tr>\n","      <th>3030</th>\n","      <td>flawless</td>\n","      <td>0.120522</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07cc4dcf-b12c-43bb-a435-18038728c335')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-07cc4dcf-b12c-43bb-a435-18038728c335 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-07cc4dcf-b12c-43bb-a435-18038728c335');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":67}],"source":["en_coeffs_df.sort_values('weight', ascending=False).head(15)"]},{"cell_type":"markdown","metadata":{"id":"cu4P7NcWxISJ"},"source":["Are there words with _literarily_ zero importance for predicting sentiment? Yes, and most of them!"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1667173983814,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"OrwQkYiGxISJ","outputId":"26e4aac3-cd7c-45c4-c6a3-ea8c3c3cfd36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(19610, 2)"]},"metadata":{},"execution_count":68}],"source":["en_coeffs_df.query('weight == 0.0').shape"]},{"cell_type":"markdown","metadata":{"id":"BbIgAsg6xISJ"},"source":["In fact, approximately 95% of features are not needed to achieve a __better__ performance than all previous models!"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667173983815,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"HNyxu1xfxISJ","outputId":"dbac112f-cd97-4763-81db-b58112ef2778"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9503271141264841"]},"metadata":{},"execution_count":69}],"source":["en_coeffs_df.query('weight == 0.0').shape[0]/en_coeffs_df.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"wcdWdDSoxISK"},"source":["Let's look at these _neutral_ words"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1667173983998,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"sbxPy3QmxISK","outputId":"98c67072-4948-4e48-e0ea-a3de304e216d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          word  weight\n","0           br     0.0\n","3         film     0.0\n","5         like     0.0\n","9        story     0.0\n","10      really     0.0\n","11      people     0.0\n","14         don     0.0\n","15         way     0.0\n","17      movies     0.0\n","18       think     0.0\n","19  characters     0.0\n","20   character     0.0\n","29      little     0.0\n","31        know     0.0\n","32         man     0.0"],"text/html":["\n","  <div id=\"df-21b6bb11-166a-43d5-89cb-b7121afb0af5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>br</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>film</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>like</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>story</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>really</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>people</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>don</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>way</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>movies</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>think</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>characters</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>character</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>little</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>know</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>man</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21b6bb11-166a-43d5-89cb-b7121afb0af5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-21b6bb11-166a-43d5-89cb-b7121afb0af5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-21b6bb11-166a-43d5-89cb-b7121afb0af5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":70}],"source":["en_coeffs_df.query('weight == 0.0').head(15)"]},{"cell_type":"markdown","metadata":{"id":"nFXniMUHxISK"},"source":["But, did we choose the right $\\lambda$ and $\\alpha$ parameters? We should run an experiment where we try different combinations of them. Fortunately, Spark let us do this by using a grid - a method that generates combination of parameters."]},{"cell_type":"code","execution_count":71,"metadata":{"id":"AAF3xjmFxISK","executionInfo":{"status":"ok","timestamp":1667173983999,"user_tz":240,"elapsed":8,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml.tuning import ParamGridBuilder"]},{"cell_type":"markdown","metadata":{"id":"zDLfkNS3xISL"},"source":["We need to build a new estimator pipeline"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667173983999,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"r4mVmwsyxISL","outputId":"777af3a0-cfc9-4b80-9f7e-7d049ea7046d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[RegexTokenizer_ea3ab32d7b41,\n"," StopWordsRemover_9a0ed8171dda,\n"," CountVectorizer_d67b188f4569,\n"," IDF_1139ff8992f7,\n"," LogisticRegression_0ace9337f373]"]},"metadata":{},"execution_count":72}],"source":["en_lr_estimator.getStages()"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"bfDztTmFxISL","executionInfo":{"status":"ok","timestamp":1667173984000,"user_tz":240,"elapsed":7,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["grid = ParamGridBuilder().\\\n","    addGrid(en_lr.regParam, [0., 0.01, 0.02]).\\\n","    addGrid(en_lr.elasticNetParam, [0., 0.2, 0.4]).\\\n","    build()"]},{"cell_type":"markdown","metadata":{"id":"A0JpwIb9xISL"},"source":["This is the list of parameters that we will try:"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667173984000,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"},"user_tz":240},"id":"jdZNyuFexISL","outputId":"ec4276c6-70a2-4a96-baac-15b0b4495323"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n"," {Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n","  Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4}]"]},"metadata":{},"execution_count":74}],"source":["grid"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhUkkqV5xISL","outputId":"cc4bc03a-0ff4-4f6f-828c-884a3588a030","executionInfo":{"status":"ok","timestamp":1667174203023,"user_tz":240,"elapsed":219026,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting model 1\n","Fitting model 2\n","Fitting model 3\n","Fitting model 4\n","Fitting model 5\n","Fitting model 6\n","Fitting model 7\n","Fitting model 8\n","Fitting model 9\n"]}],"source":["all_models = []\n","for j in range(len(grid)):\n","    print(\"Fitting model {}\".format(j+1))\n","    model = en_lr_estimator.fit(training_df, grid[j])\n","    all_models.append(model)"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"YZfyA3qUxISM","executionInfo":{"status":"ok","timestamp":1667174228711,"user_tz":240,"elapsed":25702,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["# estimate the accuracy of each of them:\n","accuracies = [m.\\\n","    transform(validation_df).\\\n","    select(fn.avg(fn.expr('float(score = prediction)')).alias('accuracy')).\\\n","    first().\\\n","    accuracy for m in all_models]"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"Obo3xiErxISM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174228712,"user_tz":240,"elapsed":27,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"d1e92938-3249-4bfd-8210-d9d602367ee3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.8391979816757402,\n"," 0.8391979816757402,\n"," 0.8391979816757402,\n"," 0.8632319745053778,\n"," 0.8794316823794981,\n"," 0.8729252423316957,\n"," 0.8680122161731509,\n"," 0.8761120701102111,\n"," 0.8600451467268623]"]},"metadata":{},"execution_count":77}],"source":["accuracies"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"jSYsJaASxISM","executionInfo":{"status":"ok","timestamp":1667174228712,"user_tz":240,"elapsed":24,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"_qz-Q6v6xISM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174228713,"user_tz":240,"elapsed":25,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"5c0dedfc-7323-481c-ceda-20acd22da2a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["best model index = 4\n"]}],"source":["best_model_idx = np.argmax(accuracies)\n","print(\"best model index =\", best_model_idx)"]},{"cell_type":"markdown","metadata":{"id":"tO8-p4IbxISM"},"source":["So the best model we found has the following parameters"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"9s3um-1nxISN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174228713,"user_tz":240,"elapsed":21,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"f062c9a1-d1c2-4a68-a956-1298a29be7d7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{Param(parent='LogisticRegression_0ace9337f373', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n"," Param(parent='LogisticRegression_0ace9337f373', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2}"]},"metadata":{},"execution_count":80}],"source":["grid[best_model_idx]"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"GElekp7dxISN","executionInfo":{"status":"ok","timestamp":1667174228713,"user_tz":240,"elapsed":19,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["best_model = all_models[best_model_idx]"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"4P2r_vaNxISN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174228714,"user_tz":240,"elapsed":19,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"182313d2-21ac-4d12-e72e-0e2e6fcaf353"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8794316823794981"]},"metadata":{},"execution_count":82}],"source":["accuracies[best_model_idx]"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"ebrLnj1bxISN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174230304,"user_tz":240,"elapsed":1607,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"70c254b1-4b81-42ba-ac8f-264b05bcfe4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------+\n","|          accuracy|\n","+------------------+\n","|0.8691663342640606|\n","+------------------+\n","\n"]}],"source":["# estimate generalization performance\n","best_model.\\\n","    transform(testing_df).\\\n","    select(fn.avg(fn.expr('float(score = prediction)')).alias('accuracy')).\\\n","    show()"]},{"cell_type":"markdown","metadata":{"id":"3bIbQhv0xISO"},"source":["## Finally, predicting tweet sentiments"]},{"cell_type":"markdown","metadata":{"id":"SZYNbPXtxISO"},"source":["Now we can use this model to predict sentiments on Twitter"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"RLI5HKnBxISO","executionInfo":{"status":"ok","timestamp":1667174230305,"user_tz":240,"elapsed":4,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["tweets_df = spark.read.parquet('tweets.parquet')"]},{"cell_type":"markdown","metadata":{"id":"PeEWPfH6xISU"},"source":["We have 1K tweets from each candidate"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"wenm1OJDxISU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174230720,"user_tz":240,"elapsed":418,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"91b6f47b-2e91-43cb-fba8-b500407b4f7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------+--------+\n","|          handle|count(1)|\n","+----------------+--------+\n","| @HillaryClinton|    1000|\n","|@realDonaldTrump|    1000|\n","+----------------+--------+\n","\n"]}],"source":["tweets_df.groupby('handle').agg(fn.count('*')).show()"]},{"cell_type":"markdown","metadata":{"id":"hwuNJabRxISU"},"source":["We can now predict the sentiment of the Tweet using our best model, we need to rename the column so that it matches our previous pipeline (`review` => ...)"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"IrjY9tGkxISV","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174230961,"user_tz":240,"elapsed":243,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"9fb1298c-e9b9-424d-9185-efbdf9e85c72"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------+--------------------+----------+\n","|         handle|              review|prediction|\n","+---------------+--------------------+----------+\n","|@HillaryClinton|RT @ZekeJMiller: ...|       1.0|\n","|@HillaryClinton|“She’s just out t...|       1.0|\n","|@HillaryClinton|We're going to ma...|       0.0|\n","|@HillaryClinton|Don't boo. Vote! ...|       0.0|\n","|@HillaryClinton|This Republican d...|       0.0|\n","|@HillaryClinton|Hillary teamed up...|       1.0|\n","|@HillaryClinton|RT @mayaharris_: ...|       1.0|\n","|@HillaryClinton|\"It was overwhelm...|       1.0|\n","|@HillaryClinton|Great step forwar...|       1.0|\n","|@HillaryClinton|\"I feel like I'm ...|       1.0|\n","|@HillaryClinton|Nobody here was “...|       1.0|\n","|@HillaryClinton|For those few peo...|       0.0|\n","|@HillaryClinton|Remember, don't b...|       1.0|\n","|@HillaryClinton|Too many talented...|       1.0|\n","|@HillaryClinton|There are hundred...|       0.0|\n","|@HillaryClinton|It's 3:20am. As g...|       1.0|\n","|@HillaryClinton|Trump stood on a ...|       0.0|\n","|@HillaryClinton|Donald Trump said...|       1.0|\n","|@HillaryClinton|RT @timkaine: 39 ...|       1.0|\n","|@HillaryClinton|Trump wants to br...|       1.0|\n","+---------------+--------------------+----------+\n","only showing top 20 rows\n","\n"]}],"source":["best_model.transform(tweets_df.withColumnRenamed('text', 'review')).select('handle', 'review', 'prediction').show()"]},{"cell_type":"markdown","metadata":{"id":"OhLKbJVZxISV"},"source":["Now, lets summarize our results in a graph!"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"kLcWEjtNxISV","executionInfo":{"status":"ok","timestamp":1667174230962,"user_tz":240,"elapsed":3,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"fZ86tS7RxISV","executionInfo":{"status":"ok","timestamp":1667174231698,"user_tz":240,"elapsed":739,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["import seaborn"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"Lvxv2eb7xISV","executionInfo":{"status":"ok","timestamp":1667174232636,"user_tz":240,"elapsed":940,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["sentiment_pd = best_model.\\\n","    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n","    groupby('handle').\\\n","    agg(fn.avg('prediction').alias('ave_prediction'), (2*fn.stddev('prediction')/fn.sqrt(fn.count('*'))).alias('std_err')).\\\n","    toPandas()"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"qb8S8PHPxISV","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1667174232638,"user_tz":240,"elapsed":8,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"75ab8510-80e6-4c73-b32f-6bf07831827a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             handle  ave_prediction   std_err\n","0   @HillaryClinton           0.573  0.031300\n","1  @realDonaldTrump           0.702  0.028942"],"text/html":["\n","  <div id=\"df-787e913b-a017-458d-b275-69d63131314b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>handle</th>\n","      <th>ave_prediction</th>\n","      <th>std_err</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@HillaryClinton</td>\n","      <td>0.573</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@realDonaldTrump</td>\n","      <td>0.702</td>\n","      <td>0.028942</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-787e913b-a017-458d-b275-69d63131314b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-787e913b-a017-458d-b275-69d63131314b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-787e913b-a017-458d-b275-69d63131314b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":90}],"source":["sentiment_pd.head()"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"CLbqlOs6xISW","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1667174232896,"user_tz":240,"elapsed":264,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"cb9b94e1-3bc8-4dc6-dfeb-9a6c95089194"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdEAAAD4CAYAAACzF9zRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYqUlEQVR4nO3df5xVdb3v8ddHQBF/EA8JpVBBDyryMx1R0wT1aHb0aJQnMe0gnnuscyuvdvLKvdqvoybpqaMWR6Nu2jEtupgdOz76cUjJq4I2o4A/wErDG10zRCFRUcTP/WOvoXEYZvYsZ8+eDa/n4zEP9l5r7bXesxh4z/e71uyJzESSJHXfDvUOIElSo7JEJUkqyRKVJKkkS1SSpJIsUUmSSupf7wDqXUOHDs2RI0fWO4YkNYyWlpbnMvPtHa2zRLczI0eOpLm5ud4xJKlhRMTTW1vndK4kSSVZopIklWSJSpJUktdEJalGNm7cyKpVq9iwYUO9o6gKAwcOZMSIEQwYMKDq11iiklQjq1atYrfddmPkyJFERL3jqBOZyZo1a1i1ahWjRo2q+nVO50pSjWzYsIE99tjDAm0AEcEee+zR7VkDS1SSasgCbRxl/q4sUUmSSvKaqCT1kpGz7uzR/a2cfXKP7k/d50hUklR3K1euZNy4cQA0Nzdz/vnnd7r9F7/4xTc9f/e7312zbJ2xRCVJNfP66693+zVNTU1cd911nW7TvkTvv//+bh+nJ1iikrSNe//738+hhx7K2LFjmTt3LjfccAMXXXTR5vU33XQTn/jEJwD4zne+w+TJk5k0aRIf/ehH2bRp01b3u+uuu3LhhRcyduxYjj/+eFavXg3A1KlTueCCC2hqauLaa6+lpaWFKVOmcOihh/Le976XZ555BoCWlhYmTpzIxIkTmTNnzub9Lly4kFNOOQWA9evXM3PmTMaPH8+ECRO47bbbmDVrFq+88gqTJk3irLPO2pwFKj+qctFFFzFu3DjGjx/PvHnzNu9z6tSpnH766Rx00EGcddZZZOZbPreWqCRt4771rW/R0tJCc3Mz1113HdOmTeP222/fvH7evHlMnz6d5cuXM2/ePO677z6WLFlCv379uOWWW7a635deeommpiYee+wxpkyZwhe+8IXN61577bXN07Kf/OQnmT9/Pi0tLZx77rlccsklAMycOZOvfvWrLF26dKvHuOyyyxg8eDCPPPIIy5Yt47jjjmP27NnsvPPOLFmyZIt8P/jBD1iyZAlLly5lwYIFXHTRRZtL++GHH+aaa67h8ccf56mnnuK+++4rdT7b8sYiSdrGXXfddZtL83e/+x2//e1v2W+//Vi8eDGjR49mxYoVHHXUUcyZM4eWlhYOO+wwAF555RWGDRu21f3usMMOnHHGGQCcffbZfOADH9i8rnX5E088waOPPsoJJ5wAwKZNmxg+fDhr165l7dq1HHPMMQB85CMf4cc//vEWx1iwYAHf+973Nj8fMmRIp5/rvffey5lnnkm/fv3Yc889mTJlCr/85S/ZfffdmTx5MiNGjABg0qRJrFy5kqOPPrrzk9cFS1SStmELFy5kwYIFLFq0iEGDBjF16lQ2bNjA9OnT+f73v89BBx3EtGnTiAgykxkzZnDllVeWOlbbn7PcZZddgMr06tixY1m0aNGbtl27dm35T6qknXbaafPjfv36lbpe254lKkm9pB4/krJu3TqGDBnCoEGDWLFiBYsXLwZg2rRpXHHFFTz88MN86UtfAuD444/ntNNO48ILL2TYsGE8//zzvPjii+y7774d7vuNN95g/vz5TJ8+nVtvvbXDUd2BBx7I6tWrWbRoEUceeSQbN27kV7/6FWPHjuVtb3sb9957L0cfffRWp41POOEE5syZwzXXXAPACy+8wJAhQxgwYAAbN27c4n1u3/Oe9/D1r3+dGTNm8Pzzz3PPPfdw9dVXs2LFitLnsDNeE5WkbdhJJ53E66+/zpgxY5g1axZHHHEEUJkWHTNmDE8//TSTJ08G4OCDD+byyy/nxBNPZMKECZxwwgmbryd2ZJddduHBBx9k3Lhx3HXXXXz2s5/dYpsdd9yR+fPnc/HFFzNx4kQmTZq0+U7aG2+8kY9//ONMmjRpqzf5XHrppbzwwguMGzeOiRMncvfddwNw3nnnMWHChM03FrWaNm0aEyZMYOLEiRx33HFcddVV7LXXXt0/cVWKnrg7SY2jqakpm5ub6x1D2i4sX76cMWPG1DtGzey6666sX7++3jF6VEd/ZxHRkplNHW3vSFSSpJK8JipJ6tThhx/Oq6+++qZlN9988zY3Ci3DEpWkGsrMhv9NLg888EC9I/SKMpc3nc6VpBoZOHAga9as6ZF3xlFttf5S7oEDB3brdY5EJalGRowYwapVqza/HZ76toEDB25+M4ZqWaKSVCMDBgxg1KhR9Y6hGnI6V5KkkixRSZJKcjp3O/PI79cxctad9Y4hSaXV4+0Tt8aRqCRJJVmikiSVZIlKklSSJSpJUkmWqCRJJVmikiSVZIlKklSSJSpJUkmWqCRJJVmikiSVZIlKklSSJSpJUkmWqCRJJVmikiSVZIlKklSSJSpJUkmWqCRJJVmikiSVZIlKklSSJSpJUkmWqCRJJVmikiSVZIlKklRSzUs0IvaMiGsjYllEPBQR34yIvXtw/ysjYmjxeFNELImIxyJiaUT8Y0T0+OcYEQsjoqmD5edExNci4pIix5I2mZZExPk9nUWSVD/9a7nziNgfmA9cCVyUma9FxPHA7RFxRmY+2WbbACIz33gLh3wlMycV+xsG3ArsDnzuLeyz2zLzCuCKIsf61kyteuhzlSTVWU1LFLgemJGZy1oXZObPI+Js4MsRcQHwU+AB4FDgryLiQ8CHgJ2A2zPzcwAR8UNgb2AgcG1mzu3swJn5x4g4D/hlRHy+2N/1QBPwOvCpzLw7Is4BTgUGAfsXx/zvxTGvBw4Ddgbmt2ZpKyJmAv8DWAssBV7tKE9EjOzgc30sM3ct1p8OnJKZ50TETcArwLuAYcC5wN8CRwIPZOY5xWvWA98ATgT+AEzPzNWdnRdJ6kv+cOusbr9m6uKru7X9woULu32MatVsOjciDgBWZ+ayiDilmMqdHxG3ZeYK4A1gKDAa+NfMHAscWDyfDEwCDo2IY4pdnpuZh1IpwfMjYo+uMmTmU0A/KkX08cqiHA+cCXw7IgYWm04CzgDGA2e0mW6+JDObgAnAlIiY0O5zHA58ATgKOBo4uItImz/XzHy6i22HUCnNC4E7gH8BxgLjI6J1ZLsL0Fycu1+wlRF3RJwXEc0R0bzp5XVdHFaSVK1ajkQnAosjoh+V/9yPAwYDjxbrfw0E8HRmLi6WnVh8PFw835VK8dxDpTinFcv3Lpav6Uaeo4GvAmTmioh4GjigWPfzzFwHEBGPA/sCvwM+VIxm+wPDqZTksjb7PBxY2Dr6i4h5bfbZkbafa1d+lJkZEY8Az2bmI8UxHgNGAkuofCMyr9j+O8APOtpRMWqfC7DT8NFZ5fElqeb2+vDsbr9m4eyTa5CknFpP526iMtp8MjPXAmuLkoLK6HAQ8FKb7QO4MjO/3nYnETEV+EvgyMx8OSIWUpnW7VRE7Fdk+GMXm7adgt0E9I+IUcCngcMy84ViirXLY3bhpXbP2xZa+323ZnqjXb432PrfmwUpSb2olnfnPkplpPYcsH9EDI6IfYAxETGeSom2n9L8KXBuRLReJ3xncYPQYOCFokAPAo7o6uAR8XbgBuBrmZnA/wHOKtYdAOwDPNHJLnanUnrrImJP4H0dbPMAlWnePSJiAPA3XeVq59mIGFPcQTyty623tANwevH4w8C9JfYhSSqpZiPRzFxelOaBwOXA3cBTVK7vfZrKzTI7t3vNzyJiDLCocgMr64GzgZ8AH4uI5VSKb2tTojtHxBJgAJWbh24GvlKs+1fg+mJ69HXgnMx8tThOR/mXRsTDwAoqU7v3dbDNM8VNS4uo3Fi0pIvT0t4s4D+A1UAzlenr7ngJmBwRl1IZbZ/RzddLkt6CqAzSarTzSiHeAlwMLCgWHwK8IzN/VLMDbyeKH5/pVvHuNHx0Dp9xTa0iSVLNrezla6IR0VLcZLqFmr7ZQmYup/LjIx8EHqLyIyD/wJtvzpEkqSHV+sYiMnMV8LFaH2d71N1RqCSpZ/neuZIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJ/esdQL1r/DsH0zz75HrHkKRtgiNRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSrJEpUkqSRLVJKkkqoq0YgYFBGfiYhvFM9HR8QptY0mSVLfVu1I9EbgVeDI4vnvgctrkkiSpAZRbYnun5lXARsBMvNlIGqWSpKkBlBtib4WETsDCRAR+1MZmUqStN2q9pdyfw74CbB3RNwCHAWcU6tQkiQ1gqpKNDP/MyIeAo6gMo373zLzuZomkySpj+u0RCPikHaLnin+3Cci9snMh2oTS5Kkvq+rkeiXO1mXwHE9mEWSpIbSaYlm5rG9FUSSpEbT1XTuBzpbn5k/6Nk4kiQ1jq6mc/+6+HMY8G7gruL5scD9gCUqSdpudTWdOxMgIn4GHJyZzxTPhwM31TydJEl9WLVvtrB3a4EWngX2qUEeSZIaRrVvtvDziPgp8N3i+RnAgtpEkiSpMVT7ZgufKG4yek+xaG5m3l67WJIk9X3VjkRb78T1RiJJkgrV/j7RD0TEryNiXUT8KSJejIg/1TqcJEl9WbUj0auAv87M5bUMI0lSI6n27txnLVBJkt6s2pFoc0TMA35Im98j6jsWSZK2Z9WW6O7Ay8CJbZYl3mgkSdqOVfsjLjNrHUSSpEZTVYlGxEDg74CxwMDW5Zl5bo1ySZLU51V7Y9HNwF7Ae4FfACOAF2sVSpKkRlBtif5FZn4GeCkzvw2cDBxeu1iSJPV91ZboxuLPtRExDhhM5dejSZK03ar27ty5ETEEuBS4A9gV+EzNUkmS1ACqLdGbgQ8CI4FvF8v2rEUgSZIaRbUl+u/AOqCFNm+2IEnS9qzaEh2RmSfVNIkkSQ2m2huL7o+I8TVNIklSg+l0JBoRj1B5e7/+wMyIeIrKdG4AmZkTah9RkqS+qavp3FN6JYUkSQ2o0xLNzKd7K4gkSY2m2muikiSpHUtUkqSSLFFJkkqyRCVJKskSlSSpJEtUkqSSLFFJkkqq9r1ztY145PfrGDnrznrHkFRDK2efXO8I2w1HopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJDVOiEbFnRFwbEcsi4qGI+GZE7N1m/fp2258TEV8rHn8sIv62eHxTRJxePF4YEU09lG9ARMyOiF8X+RZFxPuKdSsjYmjx+P4q9nVBRAzqiVySpNppiBKNiP2BnwD3AU2ZeQjwXeD2Yl2nMvOGzPy3HsjRr5PVlwHDgXFFvvcDu3WQ5d1VHOoCwBKVpD6uf70DVOl6YEZmLmtdkJk/j4izgS9TKaytiojPA+sz85872eZ64DBgZ2B+Zn6uWL4SmAecANwWER8sSpKIGF2sOxr4e2BUZr5a5HsW+H4Hx1mfmbtGxFTg88BzwDigBTgb+CTwDuDuiHguM4+NiDOB/wkEcGdmXty6L+Ba4BTgFeC04riStgF/uHVWqddNXXx1t1+zcOHCUsfa3vX5kWhEHACszsxlEXFKMVU6PyJuy8wVwBvFVOnOEbGk9QP4p24e6pLMbAImAFMiYkKbdWsy85DMvAJYFxGTiuUzgRuBvwD+b2b+qZvHfBeVUefBwH7AUZl5HfD/gGOLAn0H8CXgOGAScFhEtH7TsAuwODMnAvdQKfItRMR5EdEcEc2bXl7XzYiSpK1phJHoRGBxMZX6OSplMhh4tFj/a2AU8EpmtpYbEXEO0J3rnR+KiPOonJPhVIqtdeQ7r8123wRmRsSngDOAycA7u/k5tXowM1cVeZcAI4F7221zGLAwM1cX290CHAP8EHgN+I9iuxYqo+UtZOZcYC7ATsNHZ8msknrZXh+eXep1C2ef3MNJtDV9fiRa2AQMBZ7MzLWZ+TTweLFuGPDHt7LziBgFfBo4PjMnAHcCA9ts8lKbx7cB76MyhdqSmWuA3wD7RMTu3Tz0q20eb6L739RszMzWUizzeknSW9AIJfoocDiVa4f7R8TgiNgHGBMR44FhRam+FbtTKcp1EbEnlZLsUGZuAH5K5TrtjcWyl4H/BVwbETsCRMTbI+JvSuZ5kT/flPQglenlocVo/EzgFyX3K0nqQX2+RDNzObAPcCBwOXA38BXgDiqjx3N74BhLgYeBFcCtVO4C7swtwBvAz9osuxRYDTweEY9SmWbt7jXSVnOBn0TE3Zn5DDCLyue9lMro999L7leS1IPiz7OBfVdEjKFSXBcDC4rFhwDvyMwf1SHPp4HBmfmZ3j72W7XT8NE5fMY19Y4hqYZWek20R0VES3Hj6RYa4hpaZi6PiFOpjPauAvpRmea8rLezRMTtwP5UbnCSJG3HGqJEAYq7WD/WB3JMq3cGSVLf0OeviUqS1FdZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJlqgkSSVZopIklWSJSpJUkiUqSVJJ/esdQL1r/DsH0zz75HrHkKRtgiNRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSrJEpUkqSRLVJKkkixRSZJKskQlSSopMrPeGdSLIuJF4Il656jSUOC5eofohkbK20hZwby11EhZoT55983Mt3e0on8vB1H9PZGZTfUOUY2IaG6UrNBYeRspK5i3lhopK/S9vE7nSpJUkiUqSVJJluj2Z269A3RDI2WFxsrbSFnBvLXUSFmhj+X1xiJJkkpyJCpJUkmWqCRJJVmi26CIOCkinoiI30TErA7W7xQR84r1D0TEyN5P+aY8XeU9JiIeiojXI+L0emRsl6ervJ+KiMcjYllE/Dwi9q1HziJLV1k/FhGPRMSSiLg3Ig6uR842eTrN22a7D0ZERkTdftShinN7TkSsLs7tkoj4L/XI2SZPl+c2Ij5UfO0+FhG39nbGdlm6Or//0ubc/ioi1tYjJ5npxzb0AfQDngT2A3YElgIHt9vmvwI3FI+nA/P6eN6RwATg34DTG+D8HgsMKh7/Q73Ob5VZd2/z+FTgJ3353Bbb7QbcAywGmvpqVuAc4Gv1Op8l8o4GHgaGFM+H9eW87bb/JPCtemR1JLrtmQz8JjOfyszXgO8Bp7Xb5jTg28Xj+cDxERG9mLGtLvNm5srMXAa8UY+A7VST9+7MfLl4uhgY0csZW1WT9U9tnu4C1PNOw2q+dgEuA74EbOjNcO1Um7WvqCbv3wNzMvMFgMz8Yy9nbKu75/dM4Lu9kqwdS3Tb807gd22eryqWdbhNZr4OrAP26JV0W6omb1/S3bx/B/y4pom2rqqsEfHxiHgSuAo4v5eydaTLvBFxCLB3Zt7Zm8E6UO3XwQeLaf35EbF370TrUDV5DwAOiIj7ImJxRJzUa+m2VPW/s+JyySjgrl7ItQVLVKqRiDgbaAKurneWzmTmnMzcH7gYuLTeebYmInYAvgL8Y72zVOlHwMjMnAD8J3+e/emr+lOZ0p1KZWT3jYh4W10TVWc6MD8zN9Xj4Jbotuf3QNvveEcUyzrcJiL6A4OBNb2SbkvV5O1LqsobEX8JXAKcmpmv9lK29rp7br8HvL+miTrXVd7dgHHAwohYCRwB3FGnm4u6PLeZuabN3/03gUN7KVtHqvlaWAXckZkbM/O3wK+olGo9dOdrdzp1msoFS3Rb9EtgdESMiogdqXyB3dFumzuAGcXj04G7srg6XwfV5O1LuswbEe8Cvk6lQOt5XamarG3/kzwZ+HUv5muv07yZuS4zh2bmyMwcSeV686mZ2dzXsgJExPA2T08Flvdivvaq+Xf2QyqjUCJiKJXp3ad6M2QbVf2/EBEHAUOARb2c78/qdfeVH7X7AP6KyneRTwKXFMv+icp/OAADgf8N/AZ4ENivj+c9jMp3yS9RGTE/1sfzLgCeBZYUH3f04azXAo8VOe8Gxvblc9tu24XU6e7cKs/tlcW5XVqc24P68rkFgsp0+ePAI8D0vpy3eP55YHY9c/q2f5IkleR0riRJJVmikiSVZIlKklSSJSpJUkmWqCRJJVmikiSVZIlKklTS/wdlLB5+9lK+xgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}],"source":["sentiment_pd.plot(x='handle', y='ave_prediction', xerr='std_err', kind='barh');"]},{"cell_type":"markdown","metadata":{"id":"9UKcLNr1xISW"},"source":["But let's examine some \"negative\" tweets by Trump"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"8BHX6hSXxISW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174233232,"user_tz":240,"elapsed":339,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"d82b3b55-1ce6-40bf-bf25-31961d4cfc14"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(review='Moderator: Hillary paid $225,000 by a Brazilian bank for a speech that called for “open borders.” That’s a quote! #Debate #BigLeagueTruth'),\n"," Row(review='TRUMP &amp; CLINTON ON IMMIGRATION\\n#Debate #BigLeagueTruth https://t.co/OP4c7Jc8Ad'),\n"," Row(review='Hillary is too weak to lead on border security-no solutions, no ideas, no credibility.She supported NAFTA, worst deal in US history. #Debate'),\n"," Row(review='One of my first acts as President will be to deport the drug lords and then secure the border. #Debate #MAGA'),\n"," Row(review='Hillary Clinton will use American tax dollars to provide amnesty for thousands of illegals. I will put… https://t.co/ZpV33TfbR6')]"]},"metadata":{},"execution_count":92}],"source":["best_model.\\\n","    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n","    where(fn.col('handle') == '@realDonaldTrump').\\\n","    where(fn.col('prediction') == 0).\\\n","    select('review').\\\n","    take(5)"]},{"cell_type":"markdown","metadata":{"id":"h4iDyeD_xISX"},"source":["And Clinton"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"R76Ipa39xISX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174233674,"user_tz":240,"elapsed":444,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"5e19640c-05f3-4bff-8b77-fa4c40be66d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(review=\"We're going to make college debt-free for everyone in America. See how much you could save with Hillary's plan at… https://t.co/Fhzkubhpj7\"),\n"," Row(review=\"Don't boo. Vote! https://t.co/tTgeqy51PU https://t.co/9un3FUVxoG\"),\n"," Row(review='This Republican dad is struggling with the idea of his daughter growing up in a country led by Donald Trump. https://t.co/Tn3rQqJJKp'),\n"," Row(review=\"For those few people knocking public service, hope you'll reconsider answering the call to help others. Because we're stronger together.\"),\n"," Row(review=\"There are hundreds of thousands more @AmeriCorps applications than spots. Horrible! Let's expand it from 75,000 annual members to 250,000.\")]"]},"metadata":{},"execution_count":93}],"source":["best_model.\\\n","    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n","    where(fn.col('handle') == '@HillaryClinton').\\\n","    where(fn.col('prediction') == 0).\\\n","    select('review').\\\n","    take(5)"]},{"cell_type":"markdown","metadata":{"id":"5IM0B9kJxISX"},"source":["As you can see, there are lots of room for improvement."]},{"cell_type":"markdown","metadata":{"id":"rcGzN0l6xISX"},"source":["## Part 2: Test yourself"]},{"cell_type":"markdown","metadata":{"id":"H6lUmyrtxISX"},"source":["1. From the IMDB dataframe (`imdb_reviews_df`), compute the average review length between positive and negative reviews. Hint: use the spark sql function `length`. In particular, as we imported the funcions with the name `fn` (using `from pyspark.sql import function as fn`), use `fn.length` with the name of the column.\n","2. In the IMDB review database, are positive reviews longer than negative reviews?\n","3. Using the sentiment dataframe `sentiments_df`, find the imdb reviews with the most number of negative words. __Hint__: You need to tokenize the `review` field in `imdb_review_df` and then join with `sentiments_df`. Finally, perform selection and summary query\n","4. Similar to 3, find the imdb review with the most number of positive words."]},{"cell_type":"markdown","metadata":{"id":"gF7QnfVAxISX"},"source":["# Part 3: On your own\n","\n","1) Using the best model fitted (`best_model`), estimate the generalization error in the testing set (`testing_df`)\n","\n","2) One way of analyzing what is wrong with a model is to examine when they fail the hardest. In our case, we could do this by looking at cases in which logistic regression is predicting with high probability a positive sentiment when in fact the actual sentiment is negative. \n","\n","To extract the probability of positive sentiment, however, we must extract it from the prediction with a custom function."]},{"cell_type":"code","execution_count":94,"metadata":{"id":"iD1r0Bo4xISX","executionInfo":{"status":"ok","timestamp":1667174233675,"user_tz":240,"elapsed":4,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":["from pyspark.ml import feature"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"e-wKa7V_xISY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667174238171,"user_tz":240,"elapsed":4499,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}},"outputId":"31c02dec-8d97-4b5f-fad1-9005d0963615"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------------------+-----+--------------------+\n","|       id|              review|score|probability_positive|\n","+---------+--------------------+-----+--------------------+\n","|    neg_0|Story of a man wh...|  0.0|  0.4858175082548142|\n","| neg_1000|The plot for Desc...|  0.0|  0.2376443341146921|\n","|neg_10003|When I was little...|  0.0|6.852763778731896E-4|\n","|neg_10006|I don't know who ...|  0.0| 0.08937014571902713|\n","|neg_10012|This movie must b...|  0.0| 0.00807299809657569|\n","|neg_10014|I saw this movie ...|  0.0| 0.45214384065604374|\n","|neg_10019|Kareena Kapoor in...|  0.0|4.943897960985044E-4|\n","|neg_10022|Summer season is ...|  0.0|  0.6565560555197536|\n","|neg_10023|Shame on Yash Raj...|  0.0|2.733943228532265E-4|\n","|neg_10024|First lesson that...|  0.0|0.038393298919600305|\n","|neg_10026|I had some expect...|  0.0|  0.5677799194251035|\n","| neg_1003|OK, I am not Japa...|  0.0| 0.16000156733407078|\n","|neg_10033|I was very disple...|  0.0| 0.35082944328476795|\n","|neg_10034|If there is one f...|  0.0|2.447259147611014E-4|\n","|neg_10036|Sometime I fail t...|  0.0|  0.5943032611771003|\n","|neg_10041|The sight of Kare...|  0.0|4.978856368853535E-6|\n","|neg_10050|A huge disappoint...|  0.0|0.005241011678886576|\n","|neg_10052|Warner Bros. made...|  0.0| 0.20654560119731125|\n","|neg_10055|I grew up on the ...|  0.0|  0.3145678048134024|\n","|neg_10058|I was fascinated ...|  0.0| 0.12545436402812293|\n","+---------+--------------------+-----+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql import types\n","\n","def probability_positive(probability_column):\n","    return float(probability_column[1])\n","func_probability_positive = fn.udf(probability_positive, types.DoubleType())\n","\n","prediction_probability_df = best_model.transform(validation_df).\\\n","    withColumn('probability_positive', func_probability_positive('probability')).\\\n","    select('id', 'review', 'score', 'probability_positive')\n","prediction_probability_df.show()"]},{"cell_type":"markdown","metadata":{"id":"BJvxIGZMxISY"},"source":["Analyze the worst predictions that are __very__ wrong and suggest some ways of improving the model. __Hint__: Do a query that would get the highest `probability_positive` values for cases where `score` is `0`, and vice versa."]},{"cell_type":"markdown","metadata":{"id":"ZypBxAaUxISY"},"source":["3) Using the best model (`best_model`), predict the sentiment of the following sentences.\n","\n","a) \"Make America great again\"\n","\n","b) \"Cats are not always the best companion\"\n","\n","c) \"This sentence is not a sentence\""]},{"cell_type":"code","execution_count":95,"metadata":{"id":"3u-MdsIkxISY","executionInfo":{"status":"ok","timestamp":1667174238172,"user_tz":240,"elapsed":15,"user":{"displayName":"Willard Williamson","userId":"04507347240949254966"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.11"},"name":"lab-sentiment_analysis","notebookId":3931299693939882},"nbformat":4,"nbformat_minor":0}