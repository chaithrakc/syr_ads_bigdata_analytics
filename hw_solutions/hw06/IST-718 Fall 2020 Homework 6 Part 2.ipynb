{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.11"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bLmKS5AHyPcb"},"source":["##### Grading Feedback"]},{"cell_type":"markdown","metadata":{"id":"WmrHfEEjfShT"},"source":["# Question 0 (-2 If not answered)\n","Please provide the following the data so we can verify your github information and ensure accurate grading:\n","- Your Name: Chaithra Kopparam Cheluvaiah\n","- Your SU ID: 326926205"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"checksum":"c51f80b694da894627ba37be28c86055","grade":false,"grade_id":"cell-b038e38b5e3072a9","locked":true,"schema_version":1,"solution":false},"id":"ZGSucvIvDWn2"},"source":["# IST 718: Big Data Analytics\n","\n","- Professors: \n","  - Willard Williamson <wewillia@syr.edu>\n","  - Emory Creel <emcreel@g.syr.edu>\n","- Faculty Assistants: \n","  - Warren Justin Fernandes <wjfernan@syr.edu>\n","  - Ruchita Hiteshkumar Harsora <\trharsora@g.syr.edu>\n","\n","## General instructions:\n","\n","- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Code from the class text books or class provided code can be copied in its entirety.__\n","- Google Colab is the official class runtime environment so you should test your code on Colab before submission.\n","- Do not modify cells marked as grading cells or marked as do not modify.\n","- Before submitting your work, remember to check for run time errors with the following procedure:\n","`Runtime `$\\rightarrow$ Factory reset runtime followed by Runtime $\\rightarrow$ Run All.  All runtime errors will result in a minimum penalty of half off.\n","- All plots shall include descriptive title and axis labels.  Plot legends shall be included where possible.  Unless stated otherwise, plots can be made using any Python plotting package.\n","- Grading feedback cells are there for graders to provide feedback to students.  Don't change or remove grading feedback cells.\n","- Don't add or remove files from your git repo.\n","- Do not change file names in your repo.  This also means don't change the title of the ipython notebook.\n","- You are free to add additional code cells around the cells marked `your code here`.\n","- import * is not allowed because it is considered a very bad coding practice and in some cases can result in a significant delay (which slows down the grading process) in loading imports.  For example, the statement `from sympy import *` is not allowed.  You must import the specific packages that you need. \n","- The graders reserve the right to deduct points for subjective things we see with your code.  For example, if we ask you to create a pandas data frame to display values from an investigation and you hard code the values, we will take points off for that.  This is only one of many different things we could find in reviewing your code.  In general, write your code like you are submitting it for a code peer review in industry.  \n","- Level of effort is part of our subjective grading.  For example, in cases where we ask for a more open ended investigation, some students put in significant effort and some students do the minimum possible to meet requirements.  In these cases, we may take points off for students who did not put in much effort as compared to students who put in a lot of effort.  We feel that the students who did a better job deserve a better grade.  We reserve the right to invoke level of effort grading at any time.\n","- Your notebook must run from start to finish without requiring manual input by the graders.  For example, do not mount your personal Google drive in your notebook as this will require graders to perform manual steps.  In short, your notebook should run from start to finish with no runtime errors and no need for graders to perform any manual steps."]},{"cell_type":"markdown","metadata":{"id":"bZzy57K4yPce"},"source":["I was very disappointed with the linear regression model accuracy releted to the insurance data set in homework 3.  In this homework, we will revisit the insurance data set and try to improve prediction scores.  Specifically, we will use random forest, gradient boosting trees, and deep learning to see if we can improve upon the scores achieved in homework 3.  Part 1 of the assignment will explore random forest and GBT.  Part 2 of the assignment will use deep learning."]},{"cell_type":"code","metadata":{"id":"hZxH4JRN3Vcj","executionInfo":{"status":"ok","timestamp":1670609490705,"user_tz":300,"elapsed":8,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"source":["# Grading Cell\n","enable_grid_search = False"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pDW3ScIk2Q_H"},"source":["The following cell is used to read the insurance data set into the colab environment.  Do not change or modify the following cell."]},{"cell_type":"code","source":["%%bash\n","# Do not change or modify this cell\n","# Need to install pyspark\n","# if pyspark is already installed, will print a message indicating pyspark already installed\n","pip install pyspark &> /dev/null\n","\n","# Download the data files from github\n","# If the data file does not exist in the colab environment\n","data_file_1=insurance.csv\n","\n","if [[ ! -f ./${data_file_1} ]]; then \n","   # download the data file from github and save it in this colab environment instance\n","   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/${data_file_1} &> /dev/null\n","fi"],"metadata":{"id":"iJu6j3SbjU2N","executionInfo":{"status":"ok","timestamp":1670609543282,"user_tz":300,"elapsed":52583,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#creating spark session and spark context\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('ist718-hw06-deeplearning').getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"xWI9ahKDQ68M","executionInfo":{"status":"ok","timestamp":1670609556691,"user_tz":300,"elapsed":13420,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["spark # checking the spark version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"xoGIXN7bRCb7","executionInfo":{"status":"ok","timestamp":1670609558938,"user_tz":300,"elapsed":2288,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"caef1907-ac17-4bb4-d5d6-f53df7db5e68"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7fdd7379aee0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://3574353db9ad:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>ist718-hw06-deeplearning</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#loading the required libraries\n","\n","# spark libraries\n","import pyspark.sql.functions as f\n","from pyspark.ml import Pipeline, feature, classification\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","\n","# non-spark libraries\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"lvnoiQV-RHWs","executionInfo":{"status":"ok","timestamp":1670609560233,"user_tz":300,"elapsed":1297,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YFz91GzJ4XFj"},"source":["Your grade for grid search problems in this assignment will be determined in part on level of effort and your model performance results as compared to other students in the class."]},{"cell_type":"markdown","source":["# Question 0 (0 pts)\n","Copy the hard coded MSE scores from part 1 question 9 below (replace the code below from part 1 question 9)."],"metadata":{"id":"I0ORqeYLl3k4"}},{"cell_type":"code","source":["# uncomment and hard code the following variables using output from above.  \n","# You can copy this code for use in part 2\n","hc_rf_train_mse = 16477454.74\n","hc_rf_validation_mse = 14688149.02\n","hc_gbt_train_mse = 16861956.02\n","hc_gbt_validation_mse = 16082586.13\n","\n","# logistic regression AUC scores from HW-03\n","hc_lr_train_auc = 0.944161973667618\n","hc_lr_validation_auc= 0.9662866844530674"],"metadata":{"id":"B8nFyFD_l_J8","executionInfo":{"status":"ok","timestamp":1670609560234,"user_tz":300,"elapsed":9,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p2XNxzBB2aZU"},"source":["# Question 1 (0 pts)\n","- This question is worth 0 points because you can just copy your code from part 1 question 1.  \n","- Read the insurance data file into a spark data frame named `medical_df`.  Drop any rows that contain NAN / Null values.  Check the schema and fix if needed.  Perform needed feature engineering using **only** a string indexer to get ready for training decision trees.  One hot encoding is not needed for random forest - do not use one hot encoding or any other transformations other than string indexing. \n","- Split the data into variables named exactly train, test, and validation. Set the spark randomSplit seed argument to 2019."]},{"cell_type":"code","metadata":{"id":"FYtA8Bkw3Aq1","executionInfo":{"status":"ok","timestamp":1670609576286,"user_tz":300,"elapsed":16059,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"source":["# reading insurance data into spark dataframe\n","medical_df = spark.read.csv('insurance.csv', header=True, inferSchema=True)\n","\n","# dropping any rows that contain NAN/Null values\n","medical_df = medical_df.dropna()\n","\n","# feature engineering - converting categorical data (sex, smoker, and region) into numerical data using String Indexer\n","feature_encoding = feature.StringIndexer(inputCols=['sex', 'smoker', 'region'], \n","                                         outputCols=['sex_indexed', 'smoker_indexed', 'region_indexed'])\\\n","                                         .fit(medical_df)\n","\n","medical_df = feature_encoding.transform(medical_df)\n","\n","# stratifying\n","median_charges = medical_df.approxQuantile('charges',probabilities=[0.5],relativeError=0)\n","median_discretizer = feature.Binarizer(threshold=median_charges[0], inputCol='charges', outputCol='rate_pool')\n","medical_df= median_discretizer.transform(medical_df)"],"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# splitting the data into train, test, and validation\n","train, test, validation = medical_df.randomSplit(weights=[0.9, 0.05, 0.05], seed=2019)\n","(train.count(), test.count(), validation.count())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2LJ_IVOsRRlO","executionInfo":{"status":"ok","timestamp":1670609578782,"user_tz":300,"elapsed":2505,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"dab9fe1b-184a-4625-b16e-6986ab9eb62a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1192, 65, 81)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tnepQUryJHKm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670609579878,"user_tz":300,"elapsed":1098,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"5853cf88-c59f-4e63-a7ad-edfb480cdd77"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- age: integer (nullable = true)\n"," |-- sex: string (nullable = true)\n"," |-- bmi: double (nullable = true)\n"," |-- children: integer (nullable = true)\n"," |-- smoker: string (nullable = true)\n"," |-- region: string (nullable = true)\n"," |-- charges: double (nullable = true)\n"," |-- sex_indexed: double (nullable = false)\n"," |-- smoker_indexed: double (nullable = false)\n"," |-- region_indexed: double (nullable = false)\n"," |-- rate_pool: double (nullable = true)\n","\n","The shape of the dataframe is: (1338, 11)\n","+---+------+------+--------+------+---------+-----------+-----------+--------------+--------------+---------+\n","|age|   sex|   bmi|children|smoker|   region|    charges|sex_indexed|smoker_indexed|region_indexed|rate_pool|\n","+---+------+------+--------+------+---------+-----------+-----------+--------------+--------------+---------+\n","| 19|female|  27.9|       0|   yes|southwest|  16884.924|        1.0|           1.0|           2.0|      1.0|\n","| 18|  male| 33.77|       1|    no|southeast|  1725.5523|        0.0|           0.0|           0.0|      0.0|\n","| 28|  male|  33.0|       3|    no|southeast|   4449.462|        0.0|           0.0|           0.0|      0.0|\n","| 33|  male|22.705|       0|    no|northwest|21984.47061|        0.0|           0.0|           1.0|      1.0|\n","| 32|  male| 28.88|       0|    no|northwest|  3866.8552|        0.0|           0.0|           1.0|      0.0|\n","| 31|female| 25.74|       0|    no|southeast|  3756.6216|        1.0|           0.0|           0.0|      0.0|\n","| 46|female| 33.44|       1|    no|southeast|  8240.5896|        1.0|           0.0|           0.0|      0.0|\n","| 37|female| 27.74|       3|    no|northwest|  7281.5056|        1.0|           0.0|           1.0|      0.0|\n","| 37|  male| 29.83|       2|    no|northeast|  6406.4107|        0.0|           0.0|           3.0|      0.0|\n","| 60|female| 25.84|       0|    no|northwest|28923.13692|        1.0|           0.0|           1.0|      1.0|\n","| 25|  male| 26.22|       0|    no|northeast|  2721.3208|        0.0|           0.0|           3.0|      0.0|\n","| 62|female| 26.29|       0|   yes|southeast| 27808.7251|        1.0|           1.0|           0.0|      1.0|\n","| 23|  male|  34.4|       0|    no|southwest|   1826.843|        0.0|           0.0|           2.0|      0.0|\n","| 56|female| 39.82|       0|    no|southeast| 11090.7178|        1.0|           0.0|           0.0|      1.0|\n","| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|        0.0|           1.0|           0.0|      1.0|\n","| 19|  male|  24.6|       1|    no|southwest|   1837.237|        0.0|           0.0|           2.0|      0.0|\n","| 52|female| 30.78|       1|    no|northeast| 10797.3362|        1.0|           0.0|           3.0|      1.0|\n","| 23|  male|23.845|       0|    no|northeast| 2395.17155|        0.0|           0.0|           3.0|      0.0|\n","| 56|  male|  40.3|       0|    no|southwest|  10602.385|        0.0|           0.0|           2.0|      1.0|\n","| 30|  male|  35.3|       0|   yes|southwest|  36837.467|        0.0|           1.0|           2.0|      1.0|\n","+---+------+------+--------+------+---------+-----------+-----------+--------------+--------------+---------+\n","only showing top 20 rows\n","\n"]}],"source":["#Print the schema\n","medical_df.printSchema()\n","#Print the shape\n","print('The shape of the dataframe is:', medical_df.toPandas().shape)\n","# print the head\n","medical_df.show()"]},{"cell_type":"markdown","metadata":{"id":"v-N1EcFY3CG2"},"source":["##### Grading Feedback Cell"]},{"cell_type":"markdown","metadata":{"id":"er1V2eZ23Hrp"},"source":["The following questions will use deep learning.  The goal is to see if we can improve upon the linear regression score from homework 3, and also compare MSE scores between deep learning and random forest / GBT. You can find the spark documentation for the spark multilayer perceptron classifier can be found [here](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.MultilayerPerceptronClassifier.html)."]},{"cell_type":"markdown","metadata":{"id":"0XwLgVI34uP6"},"source":["# Question 2 (10 pts)\n","Create and train a spark multi layer perceptron model using a grid search in the cell below.  Score your model using MSE.  You are free to use K-Fold Cross validation if you wish.  Your grid search must be entirely encapsulated in the `if enable_grid_search` if statement.  The `enable_grid_search` Boolean is defined in a grading cell above.  You will disable the grid search before you submit by setting enable_grid_search to false.  Setting enable_grid_search to false should not result in a runtime error.  You will not receive full credit if any part of your grid search is outside of the if statement or if runtime errros result from setting the `enable_grid_search` variable to false."]},{"cell_type":"code","metadata":{"id":"7gfVl99j47Sy","executionInfo":{"status":"ok","timestamp":1670609579879,"user_tz":300,"elapsed":6,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"source":["if enable_grid_search:\n","  # building MLP\n","  mlp_pipe = Pipeline(stages=[feature.VectorAssembler(inputCols=['age', 'sex_indexed', 'bmi', 'children', 'smoker_indexed', 'region_indexed'], \n","                                                      outputCol='mlp_features'),\n","                              classification.MultilayerPerceptronClassifier(featuresCol='mlp_features', layers=[6,10,10,10,10,10,2], \n","                                                                            labelCol='rate_pool', seed=12072022)])\n","  \n","  # grid search\n","  mlp_grid = ParamGridBuilder().addGrid(mlp_pipe.getStages()[-1].stepSize, [0.00000001, 0.00001, 0.0001, 0.01, 0.1, 0.5, 0.9])\\\n","                                .addGrid(mlp_pipe.getStages()[-1].blockSize, [32, 64, 128, 256, 512]).build()\n","\n","  # training all the combination of models\n","  all_mlp_models = []\n","  for index, grid in enumerate(mlp_grid):\n","    print(f'Fitting the MLP Model {index}')\n","    mlp_model = mlp_pipe.fit(train, grid)\n","    all_mlp_models.append(mlp_model)\n","\n","  # binary classification evaluator\n","  mlp_evaluator = BinaryClassificationEvaluator(labelCol=mlp_pipe.getStages()[-1].getLabelCol(),\n","                                                rawPredictionCol= mlp_pipe.getStages()[-1].getPredictionCol(),\n","                                                metricName='areaUnderROC')\n","\n","  # evaluating the models\n","  mlp_mse_scores = [mlp_evaluator.evaluate(mlp_model.transform(test)) for mlp_model in all_mlp_models]\n","  print(np.round(mlp_mse_scores,2))\n","\n","  best_mlp_model_index = np.argmax(mlp_mse_scores)\n","  print(f'best MLP model index = {best_mlp_model_index}')\n","\n","  print(mlp_grid[best_mlp_model_index].values())"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVFHESWM544r"},"source":["##### Grading Feedback Cell"]},{"cell_type":"markdown","metadata":{"id":"MQcJEwqw57e6"},"source":["# Question 3 (10 pts)\n","Create a pipeline named `best_mlp_pipe` that hard codes the tuning parameters from the best model found by the grid search in question 2 above.  Train and test best_mlp_pipe.  Score your model using MSE.  Do not use k-fold cross validation in this question.  Clearly print the resulting **train and test MSE** for `best_mlp_pipe` so it's easy for the graders to see your resulting MSEs.  Save train and test MSE scores in variables named mlp_train_mse and mlp_validation_mse."]},{"cell_type":"code","metadata":{"id":"OM-nZSd775bT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670609601107,"user_tz":300,"elapsed":21232,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"faa8a9e9-f6b9-421f-9278-80f82b185d4d"},"source":["# hyper parameters\n","LEARNING_RATE = 0.00000001\n","BATCH_SIZE = 32\n","\n","# building the model\n","best_mlp_pipe = Pipeline(stages=[feature.VectorAssembler(inputCols=['age', 'sex_indexed', 'bmi', 'children', 'smoker_indexed', 'region_indexed'], \n","                                                      outputCol='mlp_features'),\n","                                 classification.MultilayerPerceptronClassifier(featuresCol='mlp_features', layers=[6,10,10,10,10,10,2], labelCol='rate_pool',\n","                                                                               stepSize=LEARNING_RATE, blockSize= BATCH_SIZE, seed=12072022)])\n","best_mlp_model = best_mlp_pipe.fit(train)\n","\n","# model evaluation\n","best_mlp_evaluator = BinaryClassificationEvaluator(labelCol=best_mlp_pipe.getStages()[-1].getLabelCol(),\n","                                                   rawPredictionCol= best_mlp_pipe.getStages()[-1].getPredictionCol(),\n","                                                   metricName='areaUnderROC')\n","\n","mlp_train_auc = best_mlp_evaluator.evaluate(best_mlp_model.transform(train))\n","mlp_validation_auc = best_mlp_evaluator.evaluate(best_mlp_model.transform(validation))\n","\n","print(\"mlp_train_auc =\", mlp_train_auc)\n","print(\"mlp_validation_auc =\", mlp_validation_auc)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["mlp_train_auc = 0.9465411992611614\n","mlp_validation_auc = 0.9761904761904762\n"]}]},{"cell_type":"markdown","metadata":{"id":"eN6MAsAZ77vr"},"source":["##### Grading Feedback Cell"]},{"cell_type":"markdown","source":["## Question 4 (10 pts)\n","Create a pandas dataframe named `rf_gbt_mlp_mse_compare` which contains 3 columns: Model, Train MSE, and Test MSE.  Load the Model column with \"RF\", \"GBT\", or \"MLP\". Load the train and validation score columns using model train and validaiton scores (hc_rf_train_mse, hc_rf_validation_mse, hc_gbt_train_mse, hc_gbt_validation_mse, mlp_train_mse, and mlp_validaiton_mse).  \n","\n","Deep learning might be able to produce better results than decision trees.  I am not sure if that will be the case for this dataset but you will be graded in comparison to other students in the class."],"metadata":{"id":"JuRpV9erXylr"}},{"cell_type":"code","source":["rf_gbt_mlp_mse_compare = pd.DataFrame(data=list(zip(['Logistic Regression',  'MLP'],  \n","                                                    [hc_lr_train_auc, mlp_train_auc ], \n","                                                    [hc_lr_validation_auc, mlp_validation_auc])), \n","                                  columns=['Model', 'Train AUC', 'Validation AUC'])"],"metadata":{"id":"Azf4yLL0YjY6","executionInfo":{"status":"ok","timestamp":1670609601108,"user_tz":300,"elapsed":41,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Grading Cell Do Not Modify\n","display(rf_gbt_mlp_mse_compare)"],"metadata":{"id":"s4j21P8BYsig","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1670609601109,"user_tz":300,"elapsed":40,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"4d125853-98e5-41a2-b4b6-f8607c398765"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["                 Model  Train AUC  Validation AUC\n","0  Logistic Regression   0.944162        0.966287\n","1                  MLP   0.946541        0.976190"],"text/html":["\n","  <div id=\"df-c7103d2e-3b23-490a-b1b6-85102f8c570d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Train AUC</th>\n","      <th>Validation AUC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Logistic Regression</td>\n","      <td>0.944162</td>\n","      <td>0.966287</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MLP</td>\n","      <td>0.946541</td>\n","      <td>0.976190</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7103d2e-3b23-490a-b1b6-85102f8c570d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7103d2e-3b23-490a-b1b6-85102f8c570d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7103d2e-3b23-490a-b1b6-85102f8c570d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["##### Grading Feedback Cell"],"metadata":{"id":"ilMVkpyCYkeb"}},{"cell_type":"markdown","metadata":{"id":"3a7l7Rae7637"},"source":["# Question 4 (-5 pts if not performed)\n","Set the `enable_grid_search` Boolean variable to False in the grading cell at the top of this notebook.  Perform a __Runtime -> Disconnect and Delte Runtime__, __Runtime -> Run all__ test to verify there are no runtime errors.  Leave the `enable_grid_search` variable set to False and turn in your assignment."]}]}